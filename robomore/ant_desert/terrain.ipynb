{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb31a499-6dcd-4b4c-a95d-b71efbd63a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# xvfb-run -s \"-screen 0 1400x900x24\" python figure2.py 运行这一行就可以得到最终视频了\n",
    "\n",
    "import time\n",
    "from design import *\n",
    "import importlib\n",
    "import shutil\n",
    "from utils import *\n",
    "from openai import OpenAI\n",
    "from prompts import *\n",
    "import json\n",
    "import numpy as np\n",
    "from gymnasium.envs.robodesign.GPTAnt import GPTAntEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c069b1e-83ee-4864-9972-41ad322f4aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_logs_full(log_dir):\n",
    "    # 找到 .tfevents 文件\n",
    "    event_file = [f for f in os.listdir(log_dir) if f.startswith(\"events.out\")][0]\n",
    "    event_path = os.path.join(log_dir, event_file)\n",
    "\n",
    "    # 加载日志\n",
    "    event_acc = EventAccumulator(event_path)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    # 获取所有 scalar tags\n",
    "    all_tags = event_acc.Tags()[\"scalars\"]\n",
    "\n",
    "    # 筛选 reward 分量\n",
    "    reward_tags = [tag for tag in all_tags if tag.startswith(\"reward/\")]\n",
    "\n",
    "    # 加载所有 reward 分量数据（完整）\n",
    "    data_full = {}\n",
    "    for tag in reward_tags:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        values = [e.value for e in events]\n",
    "        data_full[tag] = values\n",
    "\n",
    "    # 加载 episode length（完整）\n",
    "    ep_len_tag = \"rollout/ep_len_mean\"\n",
    "    if ep_len_tag in all_tags:\n",
    "        events = event_acc.Scalars(ep_len_tag)\n",
    "        values = [e.value for e in events]\n",
    "        data_full[ep_len_tag] = values\n",
    "\n",
    "    return data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67222347-8d2d-4d11-85e9-864096dffdf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: [0.04, 0.2, 0.1, 0.3, 0.05, 0.05, 0.05, 0.01, 0.01, 0.01]\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"results/terrain\"\n",
    "log_file = os.path.join(folder_name, \"parameters.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "best_fitness = float('-inf')  \n",
    "best_morphology = None  \n",
    "best_rewardfunc = None  \n",
    "best_reward = None\n",
    "best_material = None\n",
    "best_efficiency = None\n",
    "\n",
    "morphology_nums = 4\n",
    "rewardfunc_nums = 1\n",
    "\n",
    "fitness_matrix = np.array([[None for _ in range(morphology_nums)] for _ in range(rewardfunc_nums)])\n",
    "efficiency_matrix = np.array([[None for _ in range(morphology_nums)] for _ in range(rewardfunc_nums)])\n",
    "fitness_list = []\n",
    "\n",
    "morphology_list = [f'results/terrain/assets/GPTAnt_{i}.xml' for i in range(0,morphology_nums) ]\n",
    "rewardfunc_list = [f'results/terrain/env/GPTrewardfunc_{i}.py' for i in range(0,rewardfunc_nums)]\n",
    "parameter = [0.04, 0.2, 0.1, 0.3, 0.05, 0.05, 0.05, 0.01, 0.01, 0.01]\n",
    "material = compute_ant_volume(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c9ea89-b5e5-4191-b10c-589db54b7fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 results/terrain/env/GPTrewardfunc_0.py\n",
      "0 results/terrain/assets/GPTAnt_0.xml\n",
      "Run 0\n",
      "Run 1\n",
      "Run 2\n",
      "Run 3\n",
      "Run 4\n",
      "Run 5\n",
      "Run 6\n",
      "Run 7\n",
      "Run 8\n",
      "Run 9\n",
      "Run 10\n",
      "Run 11\n",
      "Run 12\n",
      "Run 13\n",
      "Run 14\n",
      "Run 15\n",
      "Run 16\n",
      "Run 17\n",
      "Run 18\n",
      "Run 19\n",
      "Run 20\n",
      "Run 21\n",
      "Run 22\n",
      "Run 23\n",
      "Run 24\n",
      "Run 25\n",
      "Run 26\n",
      "Run 27\n",
      "Run 28\n",
      "Run 29\n",
      "Run 30\n",
      "Run 31\n",
      "Run 32\n",
      "Run 33\n",
      "Run 34\n",
      "Run 35\n",
      "Run 36\n",
      "Run 37\n",
      "Run 38\n",
      "Run 39\n",
      "Run 40\n",
      "Run 41\n",
      "Run 42\n",
      "Run 43\n",
      "Run 44\n",
      "Run 45\n",
      "Run 46\n",
      "Run 47\n",
      "Run 48\n",
      "Run 49\n",
      "Run 50\n",
      "Run 51\n",
      "Run 52\n",
      "Run 53\n",
      "Run 54\n",
      "Run 55\n",
      "Run 56\n",
      "Run 57\n",
      "Run 58\n",
      "Run 59\n",
      "Run 60\n",
      "Run 61\n",
      "Run 62\n",
      "Run 63\n",
      "Run 64\n",
      "Run 65\n",
      "Run 66\n",
      "Run 67\n",
      "Run 68\n",
      "Run 69\n",
      "Run 70\n",
      "Run 71\n",
      "Run 72\n",
      "Run 73\n",
      "Run 74\n",
      "Run 75\n",
      "Run 76\n",
      "Run 77\n",
      "Run 78\n",
      "Run 79\n",
      "Run 80\n",
      "Run 81\n",
      "Run 82\n",
      "Run 83\n",
      "Run 84\n",
      "Run 85\n",
      "Run 86\n",
      "Run 87\n",
      "Run 88\n",
      "Run 89\n",
      "Run 90\n",
      "Run 91\n",
      "Run 92\n",
      "Run 93\n",
      "Run 94\n",
      "Run 95\n",
      "Run 96\n",
      "Run 97\n",
      "Run 98\n",
      "Run 99\n",
      "Saved Origin plot CSV to: /root/autodl-tmp/Ant_desert/qpos0_origin_plot.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m model_path \u001b[38;5;241m=\u001b[39m folder_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/coarse/SAC_morphology\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_rewardfunc\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_1000000.0steps\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# model_path = Train(j,  i, folder_name, total_timesteps=1e6, callback=True)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# fitness, reward = Eva(model_path=model_path, run_steps=100, folder_name=folder_name, video=False, rewardfunc_index = i, morphology_index = j)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m fitness, _ \u001b[38;5;241m=\u001b[39m Eva_with_qpos_logging2(model_path, run_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, video \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, rewardfunc_index\u001b[38;5;241m=\u001b[39mi, morphology_index\u001b[38;5;241m=\u001b[39mj)\n\u001b[1;32m     27\u001b[0m efficiency \u001b[38;5;241m=\u001b[39m fitness\u001b[38;5;241m/\u001b[39mmaterial\n\u001b[1;32m     28\u001b[0m fitness_matrix[i][j] \u001b[38;5;241m=\u001b[39m fitness\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# 0 ground\n",
    "# 1 desert\n",
    "# 2 snow\n",
    "# 3 hills\n",
    "for i, rewardfunc in enumerate(rewardfunc_list):\n",
    "    for j, morphology in enumerate(morphology_list):\n",
    "\n",
    "        print(i, rewardfunc)\n",
    "        print(j, morphology)\n",
    "        \n",
    "        if i not in [0] or j not in [0]:\n",
    "            continue\n",
    "        \n",
    "        shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(rewardfunc, \"GPTrewardfunc.py\")         \n",
    "\n",
    "        import GPTrewardfunc\n",
    "        importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "        from GPTrewardfunc import _get_rew\n",
    "        GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "        env_name = \"GPTAntEnv\"\n",
    "        model_path = folder_name + f\"/coarse/SAC_morphology{j}_rewardfunc{i}_1000000.0steps\"\n",
    "        # model_path = Train(j,  i, folder_name, total_timesteps=1e6, callback=True)\n",
    "        # fitness, reward = Eva(model_path=model_path, run_steps=100, folder_name=folder_name, video=False, rewardfunc_index = i, morphology_index = j)\n",
    "        fitness, _ = Eva_with_qpos_logging2(model_path, run_steps=100, video = True, rewardfunc_index=i, morphology_index=j)\n",
    "        efficiency = fitness/material\n",
    "        fitness_matrix[i][j] = fitness\n",
    "        efficiency_matrix[i][j] = efficiency\n",
    "                \n",
    "        logging.info(\"___________________finish coarse optimization_____________________\")\n",
    "        logging.info(f\"morphology: {j}, rewardfunc: {i}, material cost: {material} reward: {reward} fitness: {fitness} efficiency: {efficiency}\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721c7bf-deb0-4da8-b80f-69cc3091d124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c51c27-0c81-45bc-9cca-511e2e1527ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodesign",
   "language": "python",
   "name": "robodesign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
