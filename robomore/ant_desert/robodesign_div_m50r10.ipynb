{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from design import *\n",
    "import importlib\n",
    "import shutil\n",
    "from utils import *\n",
    "from openai import OpenAI\n",
    "from prompts import *\n",
    "import json\n",
    "import numpy as np\n",
    "from gymnasium.envs.robodesign.GPTAnt import GPTAntEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import prompts\n",
    "class DGA:\n",
    "    def __init__(self):\n",
    "        # api_key = \"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\"\n",
    "        api_key = \"sk-2T1O2uaVw1ivqVqXGX4k1dRw0hU2Ndwk4IAgtvTQfbL905Wp\"\n",
    "        self.client = OpenAI(api_key=api_key, base_url = \"http://chatapi.littlewheat.com/v1\")\n",
    "        # self.model = \"gpt-3.5-turbo\"\n",
    "        self.model = \"gpt-4-turbo\"\n",
    "\n",
    "    def extract_code(self, text):\n",
    "        match = re.search(r'```python\\n(.*?)\\n```', text, re.DOTALL)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    def indent_code(self, code):\n",
    "        return \"\\n\".join(line if line.strip() else line for line in code.split(\"\\n\"))\n",
    "\n",
    "    def generate_rewardfunc(self, rewardfunc_nums, folder_name):\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a reinforcement learning reward function designer\"},\n",
    "            {\"role\": \"user\", \"content\": rewardfunc_prompts + zeroshot_rewardfunc_format}\n",
    "        ]\n",
    "\n",
    "        responses = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages, n=rewardfunc_nums\n",
    "        )\n",
    "        files = []\n",
    "        for i, choice in enumerate(responses.choices):\n",
    "            reward_code = self.extract_code(choice.message.content)\n",
    "            if reward_code:\n",
    "                full_code = self.indent_code(reward_code) + \"\\n\"\n",
    "                file_name =  f\"GPTAnt_{i}.py\"\n",
    "                file_path = os.path.join(folder_name, \"env\", file_name)\n",
    "                with open(file_path, \"w\") as fp:\n",
    "                    fp.write(full_code)\n",
    "\n",
    "                with open(file_path, \"w\") as fp:\n",
    "                    fp.write(full_code)\n",
    "                files.append(file_path)\n",
    "                print(f\"Saved: {file_path}\")\n",
    "        return files\n",
    "    \n",
    "    def generate_rewardfunc_div(self, rewardfunc_nums, folder_name):\n",
    "\n",
    "        # env_path = os.path.join(os.path.dirname(__file__), \"env\", \"ant_v5.py\")\n",
    "        # with open(env_path, \"r\") as f:\n",
    "        #     env_content = f.read().rstrip()\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a reinforcement learning reward function designer\"},\n",
    "            {\"role\": \"user\", \"content\": rewardfunc_prompts + zeroshot_rewardfunc_format}\n",
    "        ]\n",
    "\n",
    "        # 生成初始 Reward Function\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages, n=1, timeout=10\n",
    "        )\n",
    "\n",
    "        rewardfunc_files = []\n",
    "\n",
    "        initial_code = self.extract_code(response.choices[0].message.content)\n",
    "        if initial_code:\n",
    "            reward_code = \"import numpy as np\\n\" + self.indent_code(initial_code) + \"\\n\"\n",
    "\n",
    "            file_path = os.path.join(folder_name, \"env\", \"GPTrewardfunc_0.py\")\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(reward_code)\n",
    "            rewardfunc_files.append(file_path)\n",
    "            print(f\"initial Saved: {file_path}\")\n",
    "\n",
    "        # 生成不同的多样化 Reward Functions\n",
    "        for i in range(1, rewardfunc_nums):\n",
    "            diverse_messages = messages + [\n",
    "                {\"role\": \"user\", \"content\": rewardfunc_div_prompts + zeroshot_rewardfunc_format}\n",
    "            ]\n",
    "\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model, messages=diverse_messages, n=1\n",
    "            )\n",
    "\n",
    "            diverse_code = self.extract_code(response.choices[0].message.content)\n",
    "            if diverse_code:\n",
    "                reward_code =  \"import numpy as np\\n\" + self.indent_code(diverse_code) + \"\\n\"\n",
    "                file_path = os.path.join(folder_name, \"env\", f\"GPTrewardfunc_{i}.py\")\n",
    "                with open(file_path, \"w\") as fp:\n",
    "                    fp.write(reward_code)\n",
    "                rewardfunc_files.append(file_path)\n",
    "                print(f\"Saved: {file_path}\")\n",
    "\n",
    "        return rewardfunc_files\n",
    "\n",
    "    def generate_morphology(self, morphology_nums, folder_name):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful mujoco robot designer\"},\n",
    "            {\"role\": \"user\", \"content\": morphology_prompts + morphology_format}\n",
    "        ]\n",
    "        \n",
    "        responses = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={'type': 'json_object'},\n",
    "            n=morphology_nums\n",
    "        )\n",
    "\n",
    "        # 解析所有 response 里的参数\n",
    "        for i, choice in enumerate(responses.choices):\n",
    "            print(f\"Response {i}:\")\n",
    "            print(json.dumps(choice.message.content, indent=4))\n",
    "\n",
    "        parameter_list = [json.loads(choice.message.content).get('parameters', []) for choice in responses.choices]\n",
    "        material_list = [compute_ant_volume(parameter) for parameter in parameter_list]\n",
    "\n",
    "        xml_files = []\n",
    "        for i, parameter in enumerate(parameter_list):\n",
    "            if not isinstance(parameter, list):\n",
    "                print(f\"Skipping invalid parameter {i}: {parameter}\")\n",
    "                continue\n",
    "\n",
    "            xml_file = ant_design(parameter)  \n",
    "            filename = f\"GPTAnt_{i}.xml\"\n",
    "            file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "            xml_files.append(file_path)\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(xml_file)\n",
    "            print(f\"Successfully saved {filename}\")\n",
    "            \n",
    "        return xml_files, material_list, parameter_list\n",
    "    \n",
    "    def generate_morphology_div(self, morphology_nums, folder_name):\n",
    "\n",
    "        material_list = []\n",
    "        xml_files = []\n",
    "        parameter_list = []\n",
    "        \n",
    "        # 生成初始 morphology\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful mujoco robot designer\"},\n",
    "            {\"role\": \"user\", \"content\": morphology_prompts + morphology_format}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={'type': 'json_object'},\n",
    "            n=1\n",
    "        )\n",
    "        \n",
    "\n",
    "        initial_parameter = json.loads(response.choices[0].message.content)\n",
    "        parameter_list.append(initial_parameter['parameters'])\n",
    "        material_list.append(compute_ant_volume(initial_parameter['parameters']))\n",
    "        messages.append({\"role\": \"assistant\", \"content\": json.dumps(initial_parameter)})\n",
    "\n",
    "        logging.info(f\"generate initial_parameter{initial_parameter['parameters']}\" )\n",
    "\n",
    "        xml_file = ant_design(initial_parameter['parameters'])  \n",
    "\n",
    "        filename = f\"GPTAnt_0.xml\"\n",
    "        file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "        with open(file_path, \"w\") as fp:\n",
    "            fp.write(xml_file)\n",
    "\n",
    "        xml_files.append(file_path)\n",
    "\n",
    "        # 生成不同的多样化设计\n",
    "        for i in range(1, morphology_nums):\n",
    "            diverse_messages = messages + [\n",
    "                {\"role\": \"user\", \"content\": morphology_div_prompts + morphology_format}\n",
    "            ]\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=diverse_messages,\n",
    "                response_format={'type': 'json_object'},\n",
    "                n=1\n",
    "            )\n",
    "\n",
    "            diverse_parameter = json.loads(response.choices[0].message.content)\n",
    "            material_list.append(compute_ant_volume(diverse_parameter['parameters']))\n",
    "            parameter_list.append(diverse_parameter['parameters'])\n",
    "            messages.append({\"role\": \"assistant\", \"content\": json.dumps(diverse_parameter)})\n",
    "            logging.info(f\"generate diverse_parameter{ diverse_parameter['parameters']}\")\n",
    "            xml_file = ant_design(diverse_parameter['parameters'])  \n",
    "            filename = f\"GPTAnt_{i}.xml\"\n",
    "            file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(xml_file)\n",
    "            xml_files.append(file_path)\n",
    "\n",
    "        return xml_files, material_list, parameter_list\n",
    "\n",
    "\n",
    "    def improve_rewardfunc(self, best_rewardfunc, rewardfunc_list, fitness_list, folder_name, step, rewardfunc_index, morphology_index):\n",
    "        reward_improve_prompts = prompts.reward_improve_prompts\n",
    "        for reward_content, fitness in zip(rewardfunc_list, fitness_list):\n",
    "            reward_improve_prompts = reward_improve_prompts + f\"reward function:{reward_content} \\n\" + f\"fintess:{fitness}\"\n",
    "        reward_improve_prompts = reward_improve_prompts + f\"best reward function:{best_rewardfunc} \\n\" + f\"best fintess:{max(fitness_list)}\" \n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a reinforcement learning reward function designer\"},\n",
    "            {\"role\": \"user\", \"content\": rewardfunc_prompts + rewardfunc_format}\n",
    "        ]\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages\n",
    "        )\n",
    "\n",
    "        print(response)\n",
    "        reward_code = self.extract_code(response.choices[0].message.content)\n",
    "\n",
    "        if reward_code:\n",
    "            full_code = \"import numpy as np \\n\" + self.indent_code(reward_code) + \"\\n\"\n",
    "            file_name =  f\"GPTAnt_refine_{step}_{rewardfunc_index}_{morphology_index}.py\"\n",
    "            file_path = os.path.join(folder_name, \"env\", file_name)\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(full_code)\n",
    "\n",
    "        return file_path\n",
    "    \n",
    "    \n",
    "\n",
    "    def improve_morphology(self, best_parameter, parameter_list, fitness_list, folder_name, step, rewardfunc_index, morphology_index):\n",
    "        morphology_improve_prompts = prompts.morphology_improve_prompts\n",
    "        for parameter_content, fitness in zip(parameter_list, fitness_list):\n",
    "            morphology_improve_prompts = morphology_improve_prompts + f\"parameter:{parameter_content} \\n\" + f\"fintess:{fitness}\"\n",
    "        morphology_improve_prompts = morphology_improve_prompts + f\"best parameter:{best_parameter} \\n\" + f\"best fintess:{max(fitness_list)}\" \n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful mujoco robot designer\"},\n",
    "            {\"role\": \"user\", \"content\": morphology_improve_prompts + morphology_format}\n",
    "        ]\n",
    "        \n",
    "        responses = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={'type': 'json_object'},\n",
    "        )\n",
    "        print(responses)\n",
    "        parameter = json.loads(responses.choices[0].message.content).get('parameters', []) \n",
    "        print(parameter)\n",
    "        xml_file = ant_design(parameter)  \n",
    "        filename = f\"GPTAnt_refine_{step}_{rewardfunc_index}_{morphology_index}.xml\"\n",
    "        file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "\n",
    "        with open(file_path, \"w\") as fp:\n",
    "            fp.write(xml_file)\n",
    "\n",
    "        print(f\"Successfully saved {filename}\")\n",
    "        return file_path, parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "folder_name = \"results/Div_m50_r10\"\n",
    "log_file = os.path.join(folder_name, \"parameters.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# folder_name = setup_logging(div_flag=True)\n",
    "\n",
    "best_fitness = float('-inf')  \n",
    "best_morphology = None  \n",
    "best_rewardfunc = None  \n",
    "best_reward = None\n",
    "best_material = None\n",
    "best_efficiency = None\n",
    "\n",
    "morphology_nums = 50\n",
    "rewardfunc_nums = 10\n",
    "\n",
    "fitness_matrix = np.array([[None for _ in range(morphology_nums)] for _ in range(rewardfunc_nums)])\n",
    "efficiency_matrix = np.array([[None for _ in range(morphology_nums)] for _ in range(rewardfunc_nums)])\n",
    "fitness_list = []\n",
    "designer = DGA()\n",
    "\n",
    "\n",
    "\n",
    "# return file list of morphology and reward function: [GPTAnt_{i}.xml] and [GPTAnt_{j}.py]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f\"start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print configuration info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: [0.2, 0.3, 0.06, 0.2, 0.15, 0.1, 0.05, 0.02, 0.02, 0.015]\n",
      "params: [0.25, 0.35, 0.08, 0.25, 0.2, 0.15, 0.1, 0.03, 0.025, 0.02]\n",
      "params: [0.15, 0.2, 0.05, 0.15, 0.1, 0.08, 0.04, 0.015, 0.015, 0.01]\n",
      "params: [0.3, 0.45, 0.1, 0.4, 0.3, 0.25, 0.15, 0.05, 0.04, 0.03]\n",
      "params: [0.18, 0.25, 0.04, 0.12, 0.09, 0.06, 0.03, 0.02, 0.018, 0.015]\n",
      "params: [0.35, 0.5, 0.1, 0.25, 0.05, 0.15, 0.02, 0.04, 0.03, 0.025]\n",
      "params: [0.45, 0.6, 0.15, 0.35, 0.2, 0.25, 0.1, 0.07, 0.06, 0.05]\n",
      "params: [0.2, 0.1, 0.3, 0.2, 0.4, 0.15, 0.35, 0.015, 0.025, 0.02]\n",
      "params: [0.22, 0.18, 0.07, 0.1, 0.05, 0.12, 0.06, 0.025, 0.02, 0.015]\n",
      "params: [0.1, 0.15, 0.02, 0.3, 0.1, 0.05, 0.02, 0.01, 0.015, 0.01]\n",
      "params: [0.4, 0.25, 0.06, 0.2, 0.05, 0.3, 0.15, 0.03, 0.025, 0.02]\n",
      "params: [0.25, 0.1, 0.2, 0.15, 0.3, 0.1, 0.2, 0.02, 0.03, 0.02]\n",
      "params: [0.3, 0.15, 0.1, 0.05, 0.2, 0.08, 0.04, 0.02, 0.015, 0.01]\n",
      "params: [0.5, 0.2, 0.12, 0.25, 0.08, 0.3, 0.1, 0.04, 0.03, 0.025]\n",
      "params: [0.15, 0.25, 0.08, 0.12, 0.07, 0.15, 0.09, 0.015, 0.018, 0.012]\n",
      "params: [0.35, 0.05, 0.3, 0.1, 0.15, 0.05, 0.1, 0.02, 0.02, 0.015]\n",
      "params: [0.12, 0.4, 0.15, 0.45, 0.3, 0.1, 0.05, 0.02, 0.01, 0.01]\n",
      "params: [0.5, 0.05, 0.05, 0.3, 0.02, 0.25, 0.02, 0.03, 0.04, 0.03]\n",
      "params: [0.55, 0.1, 0.1, 0.3, 0.02, 0.2, 0.02, 0.04, 0.04, 0.04]\n",
      "params: [0.3, 0.4, 0.1, 0.2, 0.2, 0.15, 0.15, 0.04, 0.03, 0.03]\n",
      "params: [0.2, 0.15, 0.05, 0.1, 0.08, 0.1, 0.08, 0.015, 0.015, 0.01]\n",
      "params: [0.1, 0.05, 0.25, 0.4, 0.05, 0.2, 0.1, 0.02, 0.02, 0.015]\n",
      "params: [0.3, 0.1, 0.2, 0.35, 0.15, 0.1, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.15, 0.05, 0.1, 0.4, 0.15, 0.4, 0.2, 0.01, 0.03, 0.02]\n",
      "params: [0.1, 0.2, 0.2, 0.2, 0.05, 0.3, 0.1, 0.02, 0.02, 0.01]\n",
      "params: [0.08, 0.2, 0.05, 0.05, 0.25, 0.3, 0.15, 0.012, 0.015, 0.012]\n",
      "params: [0.15, 0.25, 0.08, 0.35, 0.2, 0.25, 0.15, 0.02, 0.025, 0.02]\n",
      "params: [0.5, 0.35, 0.25, 0.15, 0.1, 0.05, 0.03, 0.025, 0.02, 0.015]\n",
      "params: [0.12, 0.08, 0.04, 0.3, 0.02, 0.25, 0.1, 0.01, 0.015, 0.015]\n",
      "params: [0.2, 0.1, 0.3, 0.05, 0.15, 0.08, 0.04, 0.015, 0.01, 0.01]\n",
      "params: [0.4, 0.45, 0.2, 0.5, 0.3, 0.6, 0.4, 0.05, 0.04, 0.035]\n",
      "params: [0.15, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.02, 0.015, 0.015]\n",
      "params: [0.2, 0.3, 0.4, 0.2, 0.1, 0.15, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.25, 0.1, 0.15, 0.12, 0.08, 0.05, 0.03, 0.02, 0.015, 0.012]\n",
      "params: [0.18, 0.05, 0.12, 0.03, 0.2, 0.075, 0.03, 0.01, 0.015, 0.01]\n",
      "params: [0.1, 0.35, 0.25, 0.08, 0.12, 0.2, 0.15, 0.015, 0.02, 0.018]\n",
      "params: [0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.005, 0.005, 0.005]\n",
      "params: [0.3, 0.6, 0.15, 0.1, 0.05, 0.25, 0.1, 0.03, 0.02, 0.015]\n",
      "params: [0.4, 0.1, 0.05, 0.2, 0.2, 0.1, 0.08, 0.02, 0.03, 0.02]\n",
      "params: [0.5, 0.18, 0.12, 0.25, 0.15, 0.3, 0.18, 0.04, 0.035, 0.03]\n",
      "params: [0.12, 0.2, 0.08, 0.35, 0.1, 0.3, 0.2, 0.015, 0.02, 0.015]\n",
      "params: [0.08, 0.4, 0.12, 0.6, 0.25, 0.05, 0.02, 0.01, 0.015, 0.012]\n",
      "params: [0.3, 0.2, 0.4, 0.1, 0.35, 0.2, 0.25, 0.03, 0.04, 0.03]\n",
      "params: [0.3, 0.2, 0.12, 0.15, 0.1, 0.1, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.15, 0.35, 0.1, 0.2, 0.05, 0.2, 0.1, 0.02, 0.018, 0.01]\n",
      "params: [0.2, 0.1, 0.05, 0.3, 0.15, 0.05, 0.02, 0.015, 0.01, 0.005]\n",
      "params: [0.05, 0.1, 0.025, 0.1, 0.025, 0.08, 0.02, 0.01, 0.008, 0.006]\n",
      "params: [0.45, 0.2, 0.08, 0.22, 0.12, 0.36, 0.18, 0.045, 0.03, 0.025]\n",
      "params: [0.25, 0.5, 0.75, 0.3, 0.4, 0.2, 0.35, 0.05, 0.06, 0.045]\n",
      "params: [0.35, 0.1, 0.3, 0.2, 0.45, 0.6, 0.05, 0.04, 0.03, 0.025]\n"
     ]
    }
   ],
   "source": [
    "designer = DGA()\n",
    "morphology_list, material_list, parameter_list = designer.generate_morphology_div(morphology_nums, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_0.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_1.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_2.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_3.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_4.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_5.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_6.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_7.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_8.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_9.py\n"
     ]
    }
   ],
   "source": [
    "designer = DGA()\n",
    "rewardfunc_list = designer.generate_rewardfunc_div(rewardfunc_nums, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficiency_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter coarse optimization stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: [0.2, 0.3, 0.06, 0.2, 0.15, 0.1, 0.05, 0.02, 0.02, 0.015]\n",
      "params: [0.25, 0.35, 0.08, 0.25, 0.2, 0.15, 0.1, 0.03, 0.025, 0.02]\n",
      "params: [0.15, 0.2, 0.05, 0.15, 0.1, 0.08, 0.04, 0.015, 0.015, 0.01]\n",
      "params: [0.3, 0.45, 0.1, 0.4, 0.3, 0.25, 0.15, 0.05, 0.04, 0.03]\n",
      "params: [0.18, 0.25, 0.04, 0.12, 0.09, 0.06, 0.03, 0.02, 0.018, 0.015]\n",
      "params: [0.35, 0.5, 0.1, 0.25, 0.05, 0.15, 0.02, 0.04, 0.03, 0.025]\n",
      "params: [0.45, 0.6, 0.15, 0.35, 0.2, 0.25, 0.1, 0.07, 0.06, 0.05]\n",
      "params: [0.2, 0.1, 0.3, 0.2, 0.4, 0.15, 0.35, 0.015, 0.025, 0.02]\n",
      "params: [0.22, 0.18, 0.07, 0.1, 0.05, 0.12, 0.06, 0.025, 0.02, 0.015]\n",
      "params: [0.1, 0.15, 0.02, 0.3, 0.1, 0.05, 0.02, 0.01, 0.015, 0.01]\n",
      "params: [0.4, 0.25, 0.06, 0.2, 0.05, 0.3, 0.15, 0.03, 0.025, 0.02]\n",
      "params: [0.25, 0.1, 0.2, 0.15, 0.3, 0.1, 0.2, 0.02, 0.03, 0.02]\n",
      "params: [0.3, 0.15, 0.1, 0.05, 0.2, 0.08, 0.04, 0.02, 0.015, 0.01]\n",
      "params: [0.5, 0.2, 0.12, 0.25, 0.08, 0.3, 0.1, 0.04, 0.03, 0.025]\n",
      "params: [0.15, 0.25, 0.08, 0.12, 0.07, 0.15, 0.09, 0.015, 0.018, 0.012]\n",
      "params: [0.35, 0.05, 0.3, 0.1, 0.15, 0.05, 0.1, 0.02, 0.02, 0.015]\n",
      "params: [0.12, 0.4, 0.15, 0.45, 0.3, 0.1, 0.05, 0.02, 0.01, 0.01]\n",
      "params: [0.5, 0.05, 0.05, 0.3, 0.02, 0.25, 0.02, 0.03, 0.04, 0.03]\n",
      "params: [0.55, 0.1, 0.1, 0.3, 0.02, 0.2, 0.02, 0.04, 0.04, 0.04]\n",
      "params: [0.3, 0.4, 0.1, 0.2, 0.2, 0.15, 0.15, 0.04, 0.03, 0.03]\n",
      "params: [0.2, 0.15, 0.05, 0.1, 0.08, 0.1, 0.08, 0.015, 0.015, 0.01]\n",
      "params: [0.1, 0.05, 0.25, 0.4, 0.05, 0.2, 0.1, 0.02, 0.02, 0.015]\n",
      "params: [0.3, 0.1, 0.2, 0.35, 0.15, 0.1, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.15, 0.05, 0.1, 0.4, 0.15, 0.4, 0.2, 0.01, 0.03, 0.02]\n",
      "params: [0.1, 0.2, 0.2, 0.2, 0.05, 0.3, 0.1, 0.02, 0.02, 0.01]\n",
      "params: [0.08, 0.2, 0.05, 0.05, 0.25, 0.3, 0.15, 0.012, 0.015, 0.012]\n",
      "params: [0.15, 0.25, 0.08, 0.35, 0.2, 0.25, 0.15, 0.02, 0.025, 0.02]\n",
      "params: [0.5, 0.35, 0.25, 0.15, 0.1, 0.05, 0.03, 0.025, 0.02, 0.015]\n",
      "params: [0.12, 0.08, 0.04, 0.3, 0.02, 0.25, 0.1, 0.01, 0.015, 0.015]\n",
      "params: [0.2, 0.1, 0.3, 0.05, 0.15, 0.08, 0.04, 0.015, 0.01, 0.01]\n",
      "params: [0.4, 0.45, 0.2, 0.5, 0.3, 0.6, 0.4, 0.05, 0.04, 0.035]\n",
      "params: [0.15, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.02, 0.015, 0.015]\n",
      "params: [0.2, 0.3, 0.4, 0.2, 0.1, 0.15, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.25, 0.1, 0.15, 0.12, 0.08, 0.05, 0.03, 0.02, 0.015, 0.012]\n",
      "params: [0.18, 0.05, 0.12, 0.03, 0.2, 0.075, 0.03, 0.01, 0.015, 0.01]\n",
      "params: [0.1, 0.35, 0.25, 0.08, 0.12, 0.2, 0.15, 0.015, 0.02, 0.018]\n",
      "params: [0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.005, 0.005, 0.005]\n",
      "params: [0.3, 0.6, 0.15, 0.1, 0.05, 0.25, 0.1, 0.03, 0.02, 0.015]\n",
      "params: [0.4, 0.1, 0.05, 0.2, 0.2, 0.1, 0.08, 0.02, 0.03, 0.02]\n",
      "params: [0.5, 0.18, 0.12, 0.25, 0.15, 0.3, 0.18, 0.04, 0.035, 0.03]\n",
      "params: [0.12, 0.2, 0.08, 0.35, 0.1, 0.3, 0.2, 0.015, 0.02, 0.015]\n",
      "params: [0.08, 0.4, 0.12, 0.6, 0.25, 0.05, 0.02, 0.01, 0.015, 0.012]\n",
      "params: [0.3, 0.2, 0.4, 0.1, 0.35, 0.2, 0.25, 0.03, 0.04, 0.03]\n",
      "params: [0.3, 0.2, 0.12, 0.15, 0.1, 0.1, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.15, 0.35, 0.1, 0.2, 0.05, 0.2, 0.1, 0.02, 0.018, 0.01]\n",
      "params: [0.2, 0.1, 0.05, 0.3, 0.15, 0.05, 0.02, 0.015, 0.01, 0.005]\n",
      "params: [0.05, 0.1, 0.025, 0.1, 0.025, 0.08, 0.02, 0.01, 0.008, 0.006]\n",
      "params: [0.45, 0.2, 0.08, 0.22, 0.12, 0.36, 0.18, 0.045, 0.03, 0.025]\n",
      "params: [0.25, 0.5, 0.75, 0.3, 0.4, 0.2, 0.35, 0.05, 0.06, 0.045]\n",
      "params: [0.35, 0.1, 0.3, 0.2, 0.45, 0.6, 0.05, 0.04, 0.03, 0.025]\n"
     ]
    }
   ],
   "source": [
    "morphology_list = [f'results/Div_m50_r10/assets/GPTAnt_{i}.xml' for i in range(0,50) ]\n",
    "rewardfunc_list = [f'results/Div_m50_r10/env/GPTrewardfunc_{i}.py' for i in range(0,10)]\n",
    "\n",
    "parameter_list = [[0.2, 0.3, 0.06, 0.2, 0.15, 0.1, 0.05, 0.02, 0.02, 0.015],\n",
    " [0.25, 0.35, 0.08, 0.25, 0.2, 0.15, 0.1, 0.03, 0.025, 0.02],\n",
    " [0.15, 0.2, 0.05, 0.15, 0.1, 0.08, 0.04, 0.015, 0.015, 0.01],\n",
    " [0.3, 0.45, 0.1, 0.4, 0.3, 0.25, 0.15, 0.05, 0.04, 0.03],\n",
    " [0.18, 0.25, 0.04, 0.12, 0.09, 0.06, 0.03, 0.02, 0.018, 0.015],\n",
    " [0.35, 0.5, 0.1, 0.25, 0.05, 0.15, 0.02, 0.04, 0.03, 0.025],\n",
    " [0.45, 0.6, 0.15, 0.35, 0.2, 0.25, 0.1, 0.07, 0.06, 0.05],\n",
    " [0.2, 0.1, 0.3, 0.2, 0.4, 0.15, 0.35, 0.015, 0.025, 0.02],\n",
    " [0.22, 0.18, 0.07, 0.1, 0.05, 0.12, 0.06, 0.025, 0.02, 0.015],\n",
    " [0.1, 0.15, 0.02, 0.3, 0.1, 0.05, 0.02, 0.01, 0.015, 0.01],\n",
    " [0.4, 0.25, 0.06, 0.2, 0.05, 0.3, 0.15, 0.03, 0.025, 0.02],\n",
    " [0.25, 0.1, 0.2, 0.15, 0.3, 0.1, 0.2, 0.02, 0.03, 0.02],\n",
    " [0.3, 0.15, 0.1, 0.05, 0.2, 0.08, 0.04, 0.02, 0.015, 0.01],\n",
    " [0.5, 0.2, 0.12, 0.25, 0.08, 0.3, 0.1, 0.04, 0.03, 0.025],\n",
    " [0.15, 0.25, 0.08, 0.12, 0.07, 0.15, 0.09, 0.015, 0.018, 0.012],\n",
    " [0.35, 0.05, 0.3, 0.1, 0.15, 0.05, 0.1, 0.02, 0.02, 0.015],\n",
    " [0.12, 0.4, 0.15, 0.45, 0.3, 0.1, 0.05, 0.02, 0.01, 0.01],\n",
    " [0.5, 0.05, 0.05, 0.3, 0.02, 0.25, 0.02, 0.03, 0.04, 0.03],\n",
    " [0.55, 0.1, 0.1, 0.3, 0.02, 0.2, 0.02, 0.04, 0.04, 0.04],\n",
    " [0.3, 0.4, 0.1, 0.2, 0.2, 0.15, 0.15, 0.04, 0.03, 0.03],\n",
    " [0.2, 0.15, 0.05, 0.1, 0.08, 0.1, 0.08, 0.015, 0.015, 0.01],\n",
    " [0.1, 0.05, 0.25, 0.4, 0.05, 0.2, 0.1, 0.02, 0.02, 0.015],\n",
    " [0.3, 0.1, 0.2, 0.35, 0.15, 0.1, 0.05, 0.025, 0.02, 0.015],\n",
    " [0.15, 0.05, 0.1, 0.4, 0.15, 0.4, 0.2, 0.01, 0.03, 0.02],\n",
    " [0.1, 0.2, 0.2, 0.2, 0.05, 0.3, 0.1, 0.02, 0.02, 0.01],\n",
    " [0.08, 0.2, 0.05, 0.05, 0.25, 0.3, 0.15, 0.012, 0.015, 0.012],\n",
    " [0.15, 0.25, 0.08, 0.35, 0.2, 0.25, 0.15, 0.02, 0.025, 0.02],\n",
    " [0.5, 0.35, 0.25, 0.15, 0.1, 0.05, 0.03, 0.025, 0.02, 0.015],\n",
    " [0.12, 0.08, 0.04, 0.3, 0.02, 0.25, 0.1, 0.01, 0.015, 0.015],\n",
    " [0.2, 0.1, 0.3, 0.05, 0.15, 0.08, 0.04, 0.015, 0.01, 0.01],\n",
    " [0.4, 0.45, 0.2, 0.5, 0.3, 0.6, 0.4, 0.05, 0.04, 0.035],\n",
    " [0.15, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.02, 0.015, 0.015],\n",
    " [0.2, 0.3, 0.4, 0.2, 0.1, 0.15, 0.05, 0.025, 0.02, 0.015],\n",
    " [0.25, 0.1, 0.15, 0.12, 0.08, 0.05, 0.03, 0.02, 0.015, 0.012],\n",
    " [0.18, 0.05, 0.12, 0.03, 0.2, 0.075, 0.03, 0.01, 0.015, 0.01],\n",
    " [0.1, 0.35, 0.25, 0.08, 0.12, 0.2, 0.15, 0.015, 0.02, 0.018],\n",
    " [0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.005, 0.005, 0.005],\n",
    " [0.3, 0.6, 0.15, 0.1, 0.05, 0.25, 0.1, 0.03, 0.02, 0.015],\n",
    " [0.4, 0.1, 0.05, 0.2, 0.2, 0.1, 0.08, 0.02, 0.03, 0.02],\n",
    " [0.5, 0.18, 0.12, 0.25, 0.15, 0.3, 0.18, 0.04, 0.035, 0.03],\n",
    " [0.12, 0.2, 0.08, 0.35, 0.1, 0.3, 0.2, 0.015, 0.02, 0.015],\n",
    " [0.08, 0.4, 0.12, 0.6, 0.25, 0.05, 0.02, 0.01, 0.015, 0.012],\n",
    " [0.3, 0.2, 0.4, 0.1, 0.35, 0.2, 0.25, 0.03, 0.04, 0.03],\n",
    " [0.3, 0.2, 0.12, 0.15, 0.1, 0.1, 0.05, 0.025, 0.02, 0.015],\n",
    " [0.15, 0.35, 0.1, 0.2, 0.05, 0.2, 0.1, 0.02, 0.018, 0.01],\n",
    " [0.2, 0.1, 0.05, 0.3, 0.15, 0.05, 0.02, 0.015, 0.01, 0.005],\n",
    " [0.05, 0.1, 0.025, 0.1, 0.025, 0.08, 0.02, 0.01, 0.008, 0.006],\n",
    " [0.45, 0.2, 0.08, 0.22, 0.12, 0.36, 0.18, 0.045, 0.03, 0.025],\n",
    " [0.25, 0.5, 0.75, 0.3, 0.4, 0.2, 0.35, 0.05, 0.06, 0.045],\n",
    " [0.35, 0.1, 0.3, 0.2, 0.45, 0.6, 0.05, 0.04, 0.03, 0.025]]\n",
    "\n",
    "\n",
    "material_list = [compute_ant_volume(parameter) for parameter in parameter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f'folder_name:{folder_name}')\n",
    "logging.info(f'morphology_nums:{morphology_nums}')\n",
    "logging.info(f'rewardfunc_nums:{rewardfunc_nums}')\n",
    "logging.info(f'parameter_list:{parameter_list}')\n",
    "logging.info(f'morphology_list:{morphology_list}')\n",
    "logging.info(f'material_list:{material_list}')\n",
    "logging.info(f'_________________________________enter coarse optimization stage_________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, rewardfunc in enumerate(rewardfunc_list):\n",
    "    for j, morphology in enumerate(morphology_list):\n",
    "        # if i not in [0] or j not in [12]:\n",
    "        #     continue\n",
    "        print(i, rewardfunc)\n",
    "        print(j, morphology)\n",
    "        shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(rewardfunc, \"GPTrewardfunc.py\")         \n",
    "\n",
    "        import GPTrewardfunc\n",
    "        importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "        from GPTrewardfunc import _get_rew\n",
    "        GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "        env_name = \"GPTAntEnv\"\n",
    "        model_path = Train(j,  i, folder_name, total_timesteps=5e5)\n",
    "        # model_path = f\"results/div2025-03-17_15-13-46/SAC_morphology{j}_rewardfunc{i}_500000.0steps\"\n",
    "        fitness, reward = Eva(model_path)\n",
    "        material = material_list[j]\n",
    "        efficiency = fitness/material\n",
    "        fitness_matrix[i][j] = fitness\n",
    "        efficiency_matrix[i][j] = efficiency\n",
    "        \n",
    "        logging.info(\"___________________finish coarse optimization_____________________\")\n",
    "        logging.info(f\"morphology: {j}, rewardfunc: {i}, material cost: {material} reward: {reward} fitness: {fitness} efficiency: {efficiency}\")\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_fitness = fitness\n",
    "            best_morphology = morphology\n",
    "            best_efficiency = efficiency\n",
    "            best_rewardfunc = rewardfunc\n",
    "            best_material = material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "efficiency_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print coarse optimization info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f'_________________________________end coarse optimization stage_________________________________')\n",
    "logging.info(f\"Stage1: Final best morphology: {best_morphology}, Fitness: {best_fitness}, best_efficiency: {best_efficiency}, best reward function: {best_rewardfunc}, Material cost: {best_material}, Reward: {best_reward}\")\n",
    "logging.info(f'folder_name:{folder_name}')\n",
    "logging.info(f'parameter_list:{parameter_list}')\n",
    "logging.info(f'fitness_matrix:{fitness_matrix}')\n",
    "logging.info(f'efficiency_matrix:{efficiency_matrix}')\n",
    "logging.info(f'_________________________________enter fine optimization stage_________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00743603645813231"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# efficiency_matrix[:,35]\n",
    "parameter_list[35]\n",
    "material_list[35]\n",
    "# fitness_matrix[:,35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configuration of fine optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取矩阵中所有非 None 的值和它们的坐标\n",
    "all_values_with_coords = []\n",
    "for i in range(len(efficiency_matrix)):\n",
    "    for j in range(len(efficiency_matrix[0])):\n",
    "        value = efficiency_matrix[i][j]\n",
    "        if value is not None:\n",
    "            all_values_with_coords.append(((i, j), value))\n",
    "\n",
    "# 按值降序排序\n",
    "sorted_values = sorted(all_values_with_coords, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 计算前 20% 的数量（至少选1个）\n",
    "top_k = max(1, int(len(sorted_values) * 0.01))\n",
    "# 取前 20% 个坐标\n",
    "efficiency_coarse_best = [coord for coord, val in sorted_values[:top_k]]\n",
    "\n",
    "logging.info(f\"fitness_coarse_best {efficiency_coarse_best}\")\n",
    "logging.info(f\"fitness_coarse_best values {sorted_values[:top_k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 35), (9, 35), (4, 35), (6, 35), (8, 35)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_best = efficiency_coarse_best\n",
    "coarse_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter fine optimization stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_optimized_results = []  # 用来记录每个 coarse_best 的最优结果\n",
    "\n",
    "for rewardfunc_index, morphology_index in coarse_best:\n",
    "    \n",
    "    morphology = morphology_list[morphology_index]\n",
    "    parameter = parameter_list[morphology_index]\n",
    "    rewardfunc = rewardfunc_list[rewardfunc_index]\n",
    "    \n",
    "    best_efficiency = efficiency_matrix[rewardfunc_index][morphology_index]\n",
    "    best_fitness = fitness_matrix[rewardfunc_index][morphology_index]\n",
    "    best_morphology = morphology\n",
    "    best_parameter = parameter\n",
    "    best_rewardfunc = rewardfunc\n",
    "    best_material = compute_ant_volume(parameter)\n",
    "    \n",
    "    \n",
    "    logging.info(f\"Initial morphology:{morphology}\")\n",
    "    logging.info(f\"Initial parameter:{parameter}\" )\n",
    "    logging.info(f\"Initial rewardfunc:{rewardfunc}\" )\n",
    "    logging.info(f\"Initial fitness:{best_fitness}\" )\n",
    "    logging.info(f\"Initial efficiency:{best_efficiency}\" )\n",
    "\n",
    "    step = 0                     # 用来记录优化的步数\n",
    "    while True:\n",
    "        improved = False  # 标记是否有改进，方便控制循环\n",
    "        designer = DGA()\n",
    "\n",
    "        # -------- 优化 reward function --------\n",
    "        step + =1\n",
    "        improved_rewardfunc = designer.improve_rewardfunc(\n",
    "            best_rewardfunc,\n",
    "            rewardfunc_list,\n",
    "            efficiency_matrix[:, morphology_index],\n",
    "            folder_name,\n",
    "            step,\n",
    "            rewardfunc_index,\n",
    "            morphology_index\n",
    "        )\n",
    "\n",
    "        shutil.copy(best_morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(improved_rewardfunc, \"GPTrewardfunc.py\")\n",
    "        model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine')\n",
    "        improved_fitness, _ = Eva(model_path)\n",
    "        improved_material = compute_ant_volume(best_parameter)\n",
    "        improved_efficiency = improved_fitness / improved_material\n",
    "\n",
    "        if improved_efficiency > best_efficiency:\n",
    "            best_fitness = improved_fitness\n",
    "            best_rewardfunc = improved_rewardfunc\n",
    "            best_material = improved_material\n",
    "            best_efficiency = improved_efficiency\n",
    "            improved = True\n",
    "            best_step = step\n",
    "            logging.info(f\"Step{step} Reward optimization improved: material={improved_material}, fitness={improved_fitness}, efficiency={improved_efficiency}\")\n",
    "        \n",
    "        if not improved:\n",
    "            logging.info(f\"Step{step} Not improved Reward!\")\n",
    "            logging.info(\"____________________________________________\")\n",
    "            break\n",
    " \n",
    "        # -------- 优化 morphology --------\n",
    "        step + =1\n",
    "        improved_morphology, improved_parameter = designer.improve_morphology(\n",
    "            best_parameter,\n",
    "            parameter_list,\n",
    "            efficiency_matrix[rewardfunc_index, :],\n",
    "            folder_name,\n",
    "            step,\n",
    "            rewardfunc_index,\n",
    "            morphology_index\n",
    "        )\n",
    "\n",
    "        shutil.copy(improved_morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(best_rewardfunc, \"GPTrewardfunc.py\")\n",
    "        model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine')\n",
    "        improved_fitness, _ = Eva(model_path)\n",
    "        improved_material = compute_ant_volume(improved_parameter)\n",
    "        improved_efficiency = improved_fitness / improved_material\n",
    "\n",
    "        if improved_efficiency > best_efficiency:\n",
    "            best_fitness = improved_fitness\n",
    "            best_morphology = improved_morphology\n",
    "            best_parameter = improved_parameter\n",
    "            best_material = improved_material\n",
    "            best_efficiency = improved_efficiency\n",
    "            improved = True\n",
    "            best_step = step\n",
    "            logging.info(f\"Step{step} Morphology optimization improved: material={improved_material}, fitness={improved_fitness}, efficiency={improved_efficiency}\")\n",
    "\n",
    "        # -------- 没有进一步改进，跳出循环 --------\n",
    "        if not improved:\n",
    "            logging.info(f\"Step{step} improved Morphology!\")\n",
    "            logging.info(\"____________________________________________\")\n",
    "            break\n",
    "\n",
    "    # 保存当前 coarse_best 的最终最优结果\n",
    "    final_optimized_results.append({\n",
    "        \"best_step\":best_step,\n",
    "        \"best_rewardfunc\": best_rewardfunc,\n",
    "        \"best_morphology\": best_morphology,\n",
    "        \"best_parameter\": best_parameter,\n",
    "        \"best_efficiency\": best_efficiency,\n",
    "        \"best_fitness\": best_fitness,\n",
    "        \"best_material\": best_material,\n",
    "    })\n",
    "\n",
    "    logging.info(f\"Final optimized result: rewardfunc_index{rewardfunc_index} morphology_index{morphology_index} best_step: {best_step}\")\n",
    "    logging.info(f\"  Morphology: {best_morphology}\")\n",
    "    logging.info(f\"  Parameter: {best_parameter}\")\n",
    "    logging.info(f\"  Rewardfunc: {best_rewardfunc}\")\n",
    "    logging.info(f\"  Fitness: {best_fitness}\")\n",
    "    logging.info(f\"  Material: {best_material}\")\n",
    "    logging.info(f\"  Efficiency: {best_efficiency}\")\n",
    "    logging.info(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"{final_optimized_results}\")\n",
    "\n",
    "# logging.info(f\"fine optimization end: best material cost: {best_material}  fitness: {improved_fitness} merterial_efficiency: {improved_material_efficiency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_2.xml',\n",
       "  'best_parameter': [0.15,\n",
       "   0.08,\n",
       "   0.08,\n",
       "   0.2,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.1,\n",
       "   0.045,\n",
       "   0.045,\n",
       "   0.045],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_1.py',\n",
       "  'best_fitness': 50.00709516278662,\n",
       "  'best_material': 0.032392802713739434,\n",
       "  'best_material_efficiency': 1543.7717941453725},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_refine.xml',\n",
       "  'best_parameter': [0.1, 0.15, 0.15, 0.2, 0.2, 0.1, 0.1, 0.035, 0.035, 0.03],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 76.12064016353048,\n",
       "  'best_material': 0.015296916683823665,\n",
       "  'best_material_efficiency': 4976.208064467482},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_2.xml',\n",
       "  'best_parameter': [0.15,\n",
       "   0.08,\n",
       "   0.08,\n",
       "   0.2,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.1,\n",
       "   0.045,\n",
       "   0.045,\n",
       "   0.045],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_4.py',\n",
       "  'best_fitness': 47.91186877673828,\n",
       "  'best_material': 0.032392802713739434,\n",
       "  'best_material_efficiency': 1479.0899447677746},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_2.xml',\n",
       "  'best_parameter': [0.15,\n",
       "   0.08,\n",
       "   0.08,\n",
       "   0.2,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.1,\n",
       "   0.045,\n",
       "   0.045,\n",
       "   0.045],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 46.876692445993534,\n",
       "  'best_material': 0.032392802713739434,\n",
       "  'best_material_efficiency': 1447.1329591406657},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_6.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.18,\n",
       "   0.08,\n",
       "   0.16,\n",
       "   0.07,\n",
       "   0.02,\n",
       "   0.02,\n",
       "   0.015],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_1.py',\n",
       "  'best_fitness': 2.797564031764912,\n",
       "  'best_material': 0.0034561055643474374,\n",
       "  'best_material_efficiency': 809.4556082499558},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_16.xml',\n",
       "  'best_parameter': [0.1, 0.16, 0.12, 0.2, 0.18, 0.22, 0.2, 0.03, 0.03, 0.03],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_1.py',\n",
       "  'best_fitness': 11.45611295769995,\n",
       "  'best_material': 0.014213668537826164,\n",
       "  'best_material_efficiency': 805.9926912754676},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_16.xml',\n",
       "  'best_parameter': [0.1, 0.16, 0.12, 0.2, 0.18, 0.22, 0.2, 0.03, 0.03, 0.03],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_4.py',\n",
       "  'best_fitness': 9.403814273434113,\n",
       "  'best_material': 0.014213668537826164,\n",
       "  'best_material_efficiency': 661.6035999719697},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_5.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.3, 0.15, 0.15, 0.05, 0.05, 0.05],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_2.py',\n",
       "  'best_fitness': 53.23553779292581,\n",
       "  'best_material': 0.09957998711265406,\n",
       "  'best_material_efficiency': 534.6007700593581},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_refine.xml',\n",
       "  'best_parameter': [0.15,\n",
       "   0.08,\n",
       "   0.08,\n",
       "   0.2,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.1,\n",
       "   0.045,\n",
       "   0.045,\n",
       "   0.045],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 54.282457189542676,\n",
       "  'best_material': 0.032392802713739434,\n",
       "  'best_material_efficiency': 1675.7567311864227},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_6.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.18,\n",
       "   0.08,\n",
       "   0.16,\n",
       "   0.07,\n",
       "   0.02,\n",
       "   0.02,\n",
       "   0.015],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_3.py',\n",
       "  'best_fitness': 1.7192099719920422,\n",
       "  'best_material': 0.0034561055643474374,\n",
       "  'best_material_efficiency': 497.4413946515704},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_5.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.3, 0.15, 0.15, 0.05, 0.05, 0.05],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_0.py',\n",
       "  'best_fitness': 49.17542423917743,\n",
       "  'best_material': 0.09957998711265406,\n",
       "  'best_material_efficiency': 493.8283852512017},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_refine.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.18,\n",
       "   0.12,\n",
       "   0.22,\n",
       "   0.18,\n",
       "   0.25,\n",
       "   0.2,\n",
       "   0.025,\n",
       "   0.025,\n",
       "   0.02],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 17.09526809070012,\n",
       "  'best_material': 0.006722116539152539,\n",
       "  'best_material_efficiency': 2543.13771430915},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_6.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.18,\n",
       "   0.08,\n",
       "   0.16,\n",
       "   0.07,\n",
       "   0.02,\n",
       "   0.02,\n",
       "   0.015],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_2.py',\n",
       "  'best_fitness': 1.3481126532538803,\n",
       "  'best_material': 0.0034561055643474374,\n",
       "  'best_material_efficiency': 390.06697803468955},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_5.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.3, 0.15, 0.15, 0.05, 0.05, 0.05],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_3.py',\n",
       "  'best_fitness': 37.45949831697024,\n",
       "  'best_material': 0.09957998711265406,\n",
       "  'best_material_efficiency': 376.1749665080053},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_5.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.3, 0.15, 0.15, 0.05, 0.05, 0.05],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 51.09127355371987,\n",
       "  'best_material': 0.09957998711265406,\n",
       "  'best_material_efficiency': 513.0676859389499},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_refine.xml',\n",
       "  'best_parameter': [0.12,\n",
       "   0.07,\n",
       "   0.07,\n",
       "   0.18,\n",
       "   0.18,\n",
       "   0.09,\n",
       "   0.09,\n",
       "   0.04,\n",
       "   0.04,\n",
       "   0.035],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 48.89126202500207,\n",
       "  'best_material': 0.019169191655623606,\n",
       "  'best_material_efficiency': 2550.5124526551954},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_5.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.3, 0.15, 0.15, 0.05, 0.05, 0.05],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 50.90890766149771,\n",
       "  'best_material': 0.09957998711265406,\n",
       "  'best_material_efficiency': 511.2363351072225},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_6.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.18,\n",
       "   0.08,\n",
       "   0.16,\n",
       "   0.07,\n",
       "   0.02,\n",
       "   0.02,\n",
       "   0.015],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 2.0205887772301043,\n",
       "  'best_material': 0.0034561055643474374,\n",
       "  'best_material_efficiency': 584.643246454661},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_refine.xml',\n",
       "  'best_parameter': [0.15,\n",
       "   0.08,\n",
       "   0.08,\n",
       "   0.2,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.1,\n",
       "   0.045,\n",
       "   0.045,\n",
       "   0.045],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 50.376361021056226,\n",
       "  'best_material': 0.032392802713739434,\n",
       "  'best_material_efficiency': 1555.1714208319815},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_6.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.18,\n",
       "   0.08,\n",
       "   0.16,\n",
       "   0.07,\n",
       "   0.02,\n",
       "   0.02,\n",
       "   0.015],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 2.71545563635916,\n",
       "  'best_material': 0.0034561055643474374,\n",
       "  'best_material_efficiency': 785.6981176649554},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_7.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.1, 0.25, 0.1, 0.05, 0.05, 0.04],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_2.py',\n",
       "  'best_fitness': 15.003488586276386,\n",
       "  'best_material': 0.09391329548963814,\n",
       "  'best_material_efficiency': 159.75894049987613},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_7.xml',\n",
       "  'best_parameter': [0.25, 0.2, 0.15, 0.3, 0.1, 0.25, 0.1, 0.05, 0.05, 0.04],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_0.py',\n",
       "  'best_fitness': 14.50132269230905,\n",
       "  'best_material': 0.09391329548963814,\n",
       "  'best_material_efficiency': 154.41181801472447},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_refine.xml',\n",
       "  'best_parameter': [0.15,\n",
       "   0.08,\n",
       "   0.08,\n",
       "   0.2,\n",
       "   0.2,\n",
       "   0.1,\n",
       "   0.1,\n",
       "   0.045,\n",
       "   0.045,\n",
       "   0.045],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTAnt_refine.py',\n",
       "  'best_fitness': 50.848411525020666,\n",
       "  'best_material': 0.032392802713739434,\n",
       "  'best_material_efficiency': 1569.7441179874586},\n",
       " {'best_morphology': 'results/wo_diverisity_24_5/assets/GPTAnt_18.xml',\n",
       "  'best_parameter': [0.2, 0.2, 0.1, 0.3, 0.15, 0.25, 0.1, 0.05, 0.05, 0.04],\n",
       "  'best_rewardfunc': 'results/wo_diverisity_24_5/env/GPTrewardfunc_1.py',\n",
       "  'best_fitness': 7.178978286961894,\n",
       "  'best_material': 0.06174723710597316,\n",
       "  'best_material_efficiency': 116.26395970788191}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_optimized_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodesign",
   "language": "python",
   "name": "robodesign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
