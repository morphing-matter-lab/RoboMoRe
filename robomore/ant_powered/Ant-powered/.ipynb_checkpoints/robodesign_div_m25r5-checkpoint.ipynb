{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from design import *\n",
    "import importlib\n",
    "import shutil\n",
    "from utils import *\n",
    "from openai import OpenAI\n",
    "from prompts import *\n",
    "import json\n",
    "import numpy as np\n",
    "from gymnasium.envs.robodesign.GPTAnt import GPTAntEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import prompts\n",
    "class DGA:\n",
    "    def __init__(self):\n",
    "        api_key = \"sk-FdAAYf3ZI8C4uY1R1GVAk8jDuuc0qyZ3XfDfF4ijqM5gTqFk\"\n",
    "        self.client = OpenAI(api_key=api_key, base_url = \"http://chatapi.littlewheat.com/v1\")\n",
    "        # api_key = \"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\"\n",
    "        # self.client = OpenAI(api_key=api_key)\n",
    "        self.model = \"gpt-4o-mini\"\n",
    "        \n",
    "    def extract_code(self, text):\n",
    "        match = re.search(r'```python\\n(.*?)\\n```', text, re.DOTALL)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    def indent_code(self, code):\n",
    "        return \"\\n\".join(line if line.strip() else line for line in code.split(\"\\n\"))\n",
    "\n",
    "    def generate_rewardfunc(self, rewardfunc_nums, folder_name):\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a reinforcement learning reward function designer\"},\n",
    "            {\"role\": \"user\", \"content\": rewardfunc_prompts + zeroshot_rewardfunc_format}\n",
    "        ]\n",
    "\n",
    "        responses = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages, n=rewardfunc_nums\n",
    "        )\n",
    "        files = []\n",
    "        for i, choice in enumerate(responses.choices):\n",
    "            reward_code = self.extract_code(choice.message.content)\n",
    "            if reward_code:\n",
    "                full_code = self.indent_code(reward_code) + \"\\n\"\n",
    "                file_name =  f\"GPTAnt_{i}.py\"\n",
    "                file_path = os.path.join(folder_name, \"env\", file_name)\n",
    "                with open(file_path, \"w\") as fp:\n",
    "                    fp.write(full_code)\n",
    "\n",
    "                with open(file_path, \"w\") as fp:\n",
    "                    fp.write(full_code)\n",
    "                files.append(file_path)\n",
    "                print(f\"Saved: {file_path}\")\n",
    "        return files\n",
    "    \n",
    "    def generate_rewardfunc_div(self, rewardfunc_nums, folder_name):\n",
    "\n",
    "        # env_path = os.path.join(os.path.dirname(__file__), \"env\", \"ant_v5.py\")\n",
    "        # with open(env_path, \"r\") as f:\n",
    "        #     env_content = f.read().rstrip()\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a reinforcement learning reward function designer\"},\n",
    "            {\"role\": \"user\", \"content\": rewardfunc_prompts + zeroshot_rewardfunc_format}\n",
    "        ]\n",
    "\n",
    "        # 生成初始 Reward Function\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages, n=1, timeout=10\n",
    "        )\n",
    "\n",
    "        rewardfunc_files = []\n",
    "\n",
    "        initial_code = self.extract_code(response.choices[0].message.content)\n",
    "        if initial_code:\n",
    "            reward_code = \"import numpy as np\\n\" + self.indent_code(initial_code) + \"\\n\"\n",
    "\n",
    "            file_path = os.path.join(folder_name, \"env\", \"GPTrewardfunc_0.py\")\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(reward_code)\n",
    "            rewardfunc_files.append(file_path)\n",
    "            print(f\"initial Saved: {file_path}\")\n",
    "\n",
    "        # 生成不同的多样化 Reward Functions\n",
    "        for i in range(1, rewardfunc_nums):\n",
    "            diverse_messages = messages + [\n",
    "                {\"role\": \"user\", \"content\": rewardfunc_div_prompts + zeroshot_rewardfunc_format}\n",
    "            ]\n",
    "\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model, messages=diverse_messages, n=1\n",
    "            )\n",
    "\n",
    "            diverse_code = self.extract_code(response.choices[0].message.content)\n",
    "            if diverse_code:\n",
    "                reward_code =  \"import numpy as np\\n\" + self.indent_code(diverse_code) + \"\\n\"\n",
    "                file_path = os.path.join(folder_name, \"env\", f\"GPTrewardfunc_{i}.py\")\n",
    "                with open(file_path, \"w\") as fp:\n",
    "                    fp.write(reward_code)\n",
    "                rewardfunc_files.append(file_path)\n",
    "                print(f\"Saved: {file_path}\")\n",
    "\n",
    "        return rewardfunc_files\n",
    "\n",
    "    def generate_morphology(self, morphology_nums, folder_name):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful mujoco robot designer\"},\n",
    "            {\"role\": \"user\", \"content\": morphology_prompts + morphology_format}\n",
    "        ]\n",
    "        \n",
    "        responses = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={'type': 'json_object'},\n",
    "            n=morphology_nums\n",
    "        )\n",
    "\n",
    "        # 解析所有 response 里的参数\n",
    "        for i, choice in enumerate(responses.choices):\n",
    "            print(f\"Response {i}:\")\n",
    "            print(json.dumps(choice.message.content, indent=4))\n",
    "\n",
    "        parameter_list = [json.loads(choice.message.content).get('parameters', []) for choice in responses.choices]\n",
    "        material_list = [compute_ant_volume(parameter) for parameter in parameter_list]\n",
    "\n",
    "        xml_files = []\n",
    "        for i, parameter in enumerate(parameter_list):\n",
    "            if not isinstance(parameter, list):\n",
    "                print(f\"Skipping invalid parameter {i}: {parameter}\")\n",
    "                continue\n",
    "\n",
    "            xml_file = ant_design(parameter)  \n",
    "            filename = f\"GPTAnt_{i}.xml\"\n",
    "            file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "            xml_files.append(file_path)\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(xml_file)\n",
    "            print(f\"Successfully saved {filename}\")\n",
    "            \n",
    "        return xml_files, material_list, parameter_list\n",
    "    \n",
    "    def generate_morphology_div(self, morphology_nums, folder_name):\n",
    "\n",
    "        material_list = []\n",
    "        xml_files = []\n",
    "        parameter_list = []\n",
    "        \n",
    "        # 生成初始 morphology\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful mujoco robot designer\"},\n",
    "            {\"role\": \"user\", \"content\": morphology_prompts + morphology_format}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={'type': 'json_object'},\n",
    "            n=1\n",
    "        )\n",
    "        \n",
    "\n",
    "        initial_parameter = json.loads(response.choices[0].message.content)\n",
    "        parameter_list.append(initial_parameter['parameters'])\n",
    "        material_list.append(compute_ant_volume(initial_parameter['parameters']))\n",
    "        messages.append({\"role\": \"assistant\", \"content\": json.dumps(initial_parameter)})\n",
    "\n",
    "        logging.info(f\"generate initial_parameter{initial_parameter['parameters']}\" )\n",
    "\n",
    "        xml_file = ant_design(initial_parameter['parameters'])  \n",
    "\n",
    "        filename = f\"GPTAnt_0.xml\"\n",
    "        file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "        with open(file_path, \"w\") as fp:\n",
    "            fp.write(xml_file)\n",
    "\n",
    "        xml_files.append(file_path)\n",
    "\n",
    "        # 生成不同的多样化设计\n",
    "        for i in range(1, morphology_nums):\n",
    "            diverse_messages = messages + [\n",
    "                {\"role\": \"user\", \"content\": morphology_div_prompts + morphology_format}\n",
    "            ]\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=diverse_messages,\n",
    "                response_format={'type': 'json_object'},\n",
    "                n=1\n",
    "            )\n",
    "\n",
    "            diverse_parameter = json.loads(response.choices[0].message.content)\n",
    "            material_list.append(compute_ant_volume(diverse_parameter['parameters']))\n",
    "            parameter_list.append(diverse_parameter['parameters'])\n",
    "            messages.append({\"role\": \"assistant\", \"content\": json.dumps(diverse_parameter)})\n",
    "            logging.info(f\"generate diverse_parameter{ diverse_parameter['parameters']}\")\n",
    "            xml_file = ant_design(diverse_parameter['parameters'])  \n",
    "            filename = f\"GPTAnt_{i}.xml\"\n",
    "            file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(xml_file)\n",
    "            xml_files.append(file_path)\n",
    "\n",
    "        return xml_files, material_list, parameter_list\n",
    "\n",
    "\n",
    "    def improve_rewardfunc(self, best_rewardfunc, rewardfunc_list, fitness_list, folder_name, step, rewardfunc_index, morphology_index):\n",
    "        reward_improve_prompts = prompts.reward_improve_prompts\n",
    "\n",
    "        for rewardfunc_file, fitness in zip(rewardfunc_list, fitness_list):\n",
    "            with open(rewardfunc_file, \"r\") as fp:\n",
    "                reward_content = fp.read()\n",
    "            reward_improve_prompts += f\"\\nreward function:\\n{reward_content}\\nfitness: {fitness}\\n\"\n",
    "\n",
    "        with open(best_rewardfunc, \"r\") as fp:\n",
    "            best_reward_content = fp.read()\n",
    "        reward_improve_prompts += f\"\\nbest reward function:\\n{best_reward_content}\\nbest fitness: {max(fitness_list)}\\n\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a reinforcement learning reward function designer\"},\n",
    "            {\"role\": \"user\", \"content\":reward_improve_prompts+ zeroshot_rewardfunc_format}\n",
    "        ]\n",
    "        print(messages)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages\n",
    "        )\n",
    "\n",
    "        print(response)\n",
    "        reward_code = self.extract_code(response.choices[0].message.content)\n",
    "\n",
    "        if reward_code:\n",
    "            full_code = \"import numpy as np \\n\" + self.indent_code(reward_code) + \"\\n\"\n",
    "            file_name =  f\"GPTrewardfunc_refine_{step}_{rewardfunc_index}_{morphology_index}.py\"\n",
    "            file_path = os.path.join(folder_name, \"env\", file_name)\n",
    "            with open(file_path, \"w\") as fp:\n",
    "                fp.write(full_code)\n",
    "\n",
    "        return file_path\n",
    "    \n",
    "    \n",
    "\n",
    "    def improve_morphology(self, best_parameter, parameter_list, fitness_list, folder_name, step, rewardfunc_index, morphology_index):\n",
    "        morphology_improve_prompts = prompts.morphology_improve_prompts\n",
    "        for parameter_content, fitness in zip(parameter_list, fitness_list):\n",
    "            morphology_improve_prompts = morphology_improve_prompts + f\"parameter:{parameter_content} \\n\" + f\"fintess:{fitness}\"\n",
    "        morphology_improve_prompts = morphology_improve_prompts + f\"best parameter:{best_parameter} \\n\" + f\"best fintess:{max(fitness_list)}\" \n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful mujoco robot designer\"},\n",
    "            {\"role\": \"user\", \"content\": morphology_improve_prompts + morphology_format}\n",
    "        ]\n",
    "        \n",
    "        responses = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            response_format={'type': 'json_object'},\n",
    "        )\n",
    "        print(responses)\n",
    "        parameter = json.loads(responses.choices[0].message.content).get('parameters', []) \n",
    "        print(parameter)\n",
    "        xml_file = ant_design(parameter)  \n",
    "        filename = f\"GPTAnt_refine_{step}_{rewardfunc_index}_{morphology_index}.xml\"\n",
    "        file_path = os.path.join(folder_name, \"assets\", filename)\n",
    "\n",
    "        with open(file_path, \"w\") as fp:\n",
    "            fp.write(xml_file)\n",
    "\n",
    "        print(f\"Successfully saved {filename}\")\n",
    "        return file_path, parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "folder_name = \"results/Div_m25_r5\"\n",
    "log_file = os.path.join(folder_name, \"parameters.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "\n",
    "# folder_name = setup_logging(div_flag=True)\n",
    "\n",
    "best_fitness = float('-inf')  \n",
    "best_morphology = None  \n",
    "best_rewardfunc = None  \n",
    "best_reward = None\n",
    "best_material = None\n",
    "best_efficiency = None\n",
    "\n",
    "morphology_nums = 26\n",
    "rewardfunc_nums = 6\n",
    "\n",
    "fitness_matrix = np.array([[None for _ in range(morphology_nums)] for _ in range(rewardfunc_nums)])\n",
    "efficiency_matrix = np.array([[None for _ in range(morphology_nums)] for _ in range(rewardfunc_nums)])\n",
    "fitness_list = []\n",
    "designer = DGA()\n",
    "\n",
    "\n",
    "\n",
    "# return file list of morphology and reward function: [GPTAnt_{i}.xml] and [GPTAnt_{j}.py]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f\"start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print configuration info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: [0.2, 0.3, 0.06, 0.2, 0.15, 0.1, 0.05, 0.02, 0.02, 0.015]\n",
      "params: [0.25, 0.35, 0.08, 0.25, 0.2, 0.15, 0.1, 0.03, 0.025, 0.02]\n",
      "params: [0.15, 0.2, 0.05, 0.15, 0.1, 0.08, 0.04, 0.015, 0.015, 0.01]\n",
      "params: [0.3, 0.45, 0.1, 0.4, 0.3, 0.25, 0.15, 0.05, 0.04, 0.03]\n",
      "params: [0.18, 0.25, 0.04, 0.12, 0.09, 0.06, 0.03, 0.02, 0.018, 0.015]\n",
      "params: [0.35, 0.5, 0.1, 0.25, 0.05, 0.15, 0.02, 0.04, 0.03, 0.025]\n",
      "params: [0.45, 0.6, 0.15, 0.35, 0.2, 0.25, 0.1, 0.07, 0.06, 0.05]\n",
      "params: [0.2, 0.1, 0.3, 0.2, 0.4, 0.15, 0.35, 0.015, 0.025, 0.02]\n",
      "params: [0.22, 0.18, 0.07, 0.1, 0.05, 0.12, 0.06, 0.025, 0.02, 0.015]\n",
      "params: [0.1, 0.15, 0.02, 0.3, 0.1, 0.05, 0.02, 0.01, 0.015, 0.01]\n",
      "params: [0.4, 0.25, 0.06, 0.2, 0.05, 0.3, 0.15, 0.03, 0.025, 0.02]\n",
      "params: [0.25, 0.1, 0.2, 0.15, 0.3, 0.1, 0.2, 0.02, 0.03, 0.02]\n",
      "params: [0.3, 0.15, 0.1, 0.05, 0.2, 0.08, 0.04, 0.02, 0.015, 0.01]\n",
      "params: [0.5, 0.2, 0.12, 0.25, 0.08, 0.3, 0.1, 0.04, 0.03, 0.025]\n",
      "params: [0.15, 0.25, 0.08, 0.12, 0.07, 0.15, 0.09, 0.015, 0.018, 0.012]\n",
      "params: [0.35, 0.05, 0.3, 0.1, 0.15, 0.05, 0.1, 0.02, 0.02, 0.015]\n",
      "params: [0.12, 0.4, 0.15, 0.45, 0.3, 0.1, 0.05, 0.02, 0.01, 0.01]\n",
      "params: [0.5, 0.05, 0.05, 0.3, 0.02, 0.25, 0.02, 0.03, 0.04, 0.03]\n",
      "params: [0.55, 0.1, 0.1, 0.3, 0.02, 0.2, 0.02, 0.04, 0.04, 0.04]\n",
      "params: [0.3, 0.4, 0.1, 0.2, 0.2, 0.15, 0.15, 0.04, 0.03, 0.03]\n",
      "params: [0.2, 0.15, 0.05, 0.1, 0.08, 0.1, 0.08, 0.015, 0.015, 0.01]\n",
      "params: [0.1, 0.05, 0.25, 0.4, 0.05, 0.2, 0.1, 0.02, 0.02, 0.015]\n",
      "params: [0.3, 0.1, 0.2, 0.35, 0.15, 0.1, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.15, 0.05, 0.1, 0.4, 0.15, 0.4, 0.2, 0.01, 0.03, 0.02]\n",
      "params: [0.1, 0.2, 0.2, 0.2, 0.05, 0.3, 0.1, 0.02, 0.02, 0.01]\n",
      "params: [0.08, 0.2, 0.05, 0.05, 0.25, 0.3, 0.15, 0.012, 0.015, 0.012]\n",
      "params: [0.15, 0.25, 0.08, 0.35, 0.2, 0.25, 0.15, 0.02, 0.025, 0.02]\n",
      "params: [0.5, 0.35, 0.25, 0.15, 0.1, 0.05, 0.03, 0.025, 0.02, 0.015]\n",
      "params: [0.12, 0.08, 0.04, 0.3, 0.02, 0.25, 0.1, 0.01, 0.015, 0.015]\n",
      "params: [0.2, 0.1, 0.3, 0.05, 0.15, 0.08, 0.04, 0.015, 0.01, 0.01]\n",
      "params: [0.4, 0.45, 0.2, 0.5, 0.3, 0.6, 0.4, 0.05, 0.04, 0.035]\n",
      "params: [0.15, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1, 0.02, 0.015, 0.015]\n",
      "params: [0.2, 0.3, 0.4, 0.2, 0.1, 0.15, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.25, 0.1, 0.15, 0.12, 0.08, 0.05, 0.03, 0.02, 0.015, 0.012]\n",
      "params: [0.18, 0.05, 0.12, 0.03, 0.2, 0.075, 0.03, 0.01, 0.015, 0.01]\n",
      "params: [0.1, 0.35, 0.25, 0.08, 0.12, 0.2, 0.15, 0.015, 0.02, 0.018]\n",
      "params: [0.1, 0.05, 0.05, 0.02, 0.02, 0.01, 0.01, 0.005, 0.005, 0.005]\n",
      "params: [0.3, 0.6, 0.15, 0.1, 0.05, 0.25, 0.1, 0.03, 0.02, 0.015]\n",
      "params: [0.4, 0.1, 0.05, 0.2, 0.2, 0.1, 0.08, 0.02, 0.03, 0.02]\n",
      "params: [0.5, 0.18, 0.12, 0.25, 0.15, 0.3, 0.18, 0.04, 0.035, 0.03]\n",
      "params: [0.12, 0.2, 0.08, 0.35, 0.1, 0.3, 0.2, 0.015, 0.02, 0.015]\n",
      "params: [0.08, 0.4, 0.12, 0.6, 0.25, 0.05, 0.02, 0.01, 0.015, 0.012]\n",
      "params: [0.3, 0.2, 0.4, 0.1, 0.35, 0.2, 0.25, 0.03, 0.04, 0.03]\n",
      "params: [0.3, 0.2, 0.12, 0.15, 0.1, 0.1, 0.05, 0.025, 0.02, 0.015]\n",
      "params: [0.15, 0.35, 0.1, 0.2, 0.05, 0.2, 0.1, 0.02, 0.018, 0.01]\n",
      "params: [0.2, 0.1, 0.05, 0.3, 0.15, 0.05, 0.02, 0.015, 0.01, 0.005]\n",
      "params: [0.05, 0.1, 0.025, 0.1, 0.025, 0.08, 0.02, 0.01, 0.008, 0.006]\n",
      "params: [0.45, 0.2, 0.08, 0.22, 0.12, 0.36, 0.18, 0.045, 0.03, 0.025]\n",
      "params: [0.25, 0.5, 0.75, 0.3, 0.4, 0.2, 0.35, 0.05, 0.06, 0.045]\n",
      "params: [0.35, 0.1, 0.3, 0.2, 0.45, 0.6, 0.05, 0.04, 0.03, 0.025]\n"
     ]
    }
   ],
   "source": [
    "designer = DGA()\n",
    "morphology_list, material_list, parameter_list = designer.generate_morphology_div(morphology_nums, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_0.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_1.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_2.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_3.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_4.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_5.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_6.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_7.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_8.py\n",
      "Saved: results/div2025-03-21_15-03-44/env/GPTrewardfunc_9.py\n"
     ]
    }
   ],
   "source": [
    "designer = DGA()\n",
    "rewardfunc_list = designer.generate_rewardfunc_div(rewardfunc_nums, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficiency_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter coarse optimization stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: [0.3, 0.1, 0.05, 0.15, 0.1, 0.1, 0.1, 0.03, 0.03, 0.03]\n",
      "params: [0.25, 0.2, 0.1, 0.1, 0.2, 0.15, 0.15, 0.02, 0.02, 0.02]\n",
      "params: [0.15, 0.25, 0.15, 0.25, 0.1, 0.2, 0.1, 0.04, 0.04, 0.04]\n",
      "params: [0.2, 0.05, 0.1, 0.05, 0.05, 0.05, 0.05, 0.01, 0.01, 0.01]\n",
      "params: [0.4, 0.15, 0.2, 0.3, 0.15, 0.25, 0.2, 0.05, 0.05, 0.05]\n",
      "params: [0.1, 0.3, 0.2, 0.2, 0.3, 0.15, 0.1, 0.02, 0.02, 0.02]\n",
      "params: [0.5, 0.4, 0.3, 0.35, 0.25, 0.3, 0.25, 0.08, 0.06, 0.06]\n",
      "params: [0.2, 0.1, 0.2, 0.15, 0.1, 0.2, 0.15, 0.025, 0.025, 0.025]\n",
      "params: [0.35, 0.07, 0.12, 0.4, 0.2, 0.5, 0.3, 0.015, 0.015, 0.015]\n",
      "params: [0.45, 0.2, 0.05, 0.05, 0.2, 0.1, 0.05, 0.025, 0.025, 0.025]\n",
      "params: [0.6, 0.25, 0.2, 0.3, 0.45, 0.35, 0.4, 0.1, 0.08, 0.08]\n",
      "params: [0.15, 0.07, 0.08, 0.1, 0.05, 0.12, 0.06, 0.02, 0.02, 0.02]\n",
      "params: [0.5, 0.35, 0.25, 0.2, 0.3, 0.15, 0.2, 0.05, 0.05, 0.04]\n",
      "params: [0.1, 0.15, 0.05, 0.4, 0.15, 0.3, 0.2, 0.04, 0.04, 0.02]\n",
      "params: [0.25, 0.5, 0.15, 0.1, 0.25, 0.18, 0.12, 0.03, 0.02, 0.02]\n",
      "params: [0.2, 0.05, 0.1, 0.5, 0.05, 0.25, 0.05, 0.015, 0.015, 0.015]\n",
      "params: [0.35, 0.2, 0.2, 0.35, 0.2, 0.1, 0.1, 0.06, 0.06, 0.06]\n",
      "params: [0.05, 0.4, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "params: [0.1, 0.2, 0.3, 0.15, 0.25, 0.2, 0.2, 0.01, 0.015, 0.02]\n",
      "params: [0.55, 0.1, 0.05, 0.05, 0.1, 0.08, 0.03, 0.02, 0.02, 0.02]\n",
      "params: [0.3, 0.08, 0.04, 0.2, 0.1, 0.15, 0.07, 0.025, 0.03, 0.035]\n",
      "params: [0.4, 0.12, 0.18, 0.22, 0.08, 0.3, 0.15, 0.02, 0.015, 0.01]\n",
      "params: [0.25, 0.4, 0.3, 0.4, 0.3, 0.12, 0.12, 0.05, 0.04, 0.04]\n",
      "params: [0.2, 0.3, 0.15, 0.1, 0.05, 0.15, 0.2, 0.03, 0.02, 0.02]\n",
      "params: [0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015]\n",
      "params: [0.25, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.08, 0.08, 0.08]\n"
     ]
    }
   ],
   "source": [
    "morphology_list = [f'results/Div_m25_r5/assets/GPTAnt_{i}.xml' for i in range(0,26) ]\n",
    "rewardfunc_list = [f'results/Div_m25_r5/env/GPTrewardfunc_{i}.py' for i in range(0,6)]\n",
    "\n",
    "parameter_list = [[0.3, 0.1, 0.05, 0.15, 0.1, 0.1, 0.1, 0.03, 0.03, 0.03],\n",
    " [0.25, 0.2, 0.1, 0.1, 0.2, 0.15, 0.15, 0.02, 0.02, 0.02],\n",
    " [0.15, 0.25, 0.15, 0.25, 0.1, 0.2, 0.1, 0.04, 0.04, 0.04],\n",
    " [0.2, 0.05, 0.1, 0.05, 0.05, 0.05, 0.05, 0.01, 0.01, 0.01],\n",
    " [0.4, 0.15, 0.2, 0.3, 0.15, 0.25, 0.2, 0.05, 0.05, 0.05],\n",
    " [0.1, 0.3, 0.2, 0.2, 0.3, 0.15, 0.1, 0.02, 0.02, 0.02],\n",
    " [0.5, 0.4, 0.3, 0.35, 0.25, 0.3, 0.25, 0.08, 0.06, 0.06],\n",
    " [0.2, 0.1, 0.2, 0.15, 0.1, 0.2, 0.15, 0.025, 0.025, 0.025],\n",
    " [0.35, 0.07, 0.12, 0.4, 0.2, 0.5, 0.3, 0.015, 0.015, 0.015],\n",
    " [0.45, 0.2, 0.05, 0.05, 0.2, 0.1, 0.05, 0.025, 0.025, 0.025],\n",
    " [0.6, 0.25, 0.2, 0.3, 0.45, 0.35, 0.4, 0.1, 0.08, 0.08],\n",
    " [0.15, 0.07, 0.08, 0.1, 0.05, 0.12, 0.06, 0.02, 0.02, 0.02],\n",
    " [0.5, 0.35, 0.25, 0.2, 0.3, 0.15, 0.2, 0.05, 0.05, 0.04],\n",
    " [0.1, 0.15, 0.05, 0.4, 0.15, 0.3, 0.2, 0.04, 0.04, 0.02],\n",
    " [0.25, 0.5, 0.15, 0.1, 0.25, 0.18, 0.12, 0.03, 0.02, 0.02],\n",
    " [0.2, 0.05, 0.1, 0.5, 0.05, 0.25, 0.05, 0.015, 0.015, 0.015],\n",
    " [0.35, 0.2, 0.2, 0.35, 0.2, 0.1, 0.1, 0.06, 0.06, 0.06],\n",
    " [0.05, 0.4, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01],\n",
    " [0.1, 0.2, 0.3, 0.15, 0.25, 0.2, 0.2, 0.01, 0.015, 0.02],\n",
    " [0.55, 0.1, 0.05, 0.05, 0.1, 0.08, 0.03, 0.02, 0.02, 0.02],\n",
    " [0.3, 0.08, 0.04, 0.2, 0.1, 0.15, 0.07, 0.025, 0.03, 0.035],\n",
    " [0.4, 0.12, 0.18, 0.22, 0.08, 0.3, 0.15, 0.02, 0.015, 0.01],\n",
    " [0.25, 0.4, 0.3, 0.4, 0.3, 0.12, 0.12, 0.05, 0.04, 0.04],\n",
    " [0.2, 0.3, 0.15, 0.1, 0.05, 0.15, 0.2, 0.03, 0.02, 0.02],\n",
    "[0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015],\n",
    "[0.25, 0.2, 0.2, 0.2, 0.2,0.4,0.4, 0.08, 0.08, 0.08 ]\n",
    "                 ]\n",
    "\n",
    "\n",
    "material_list = [compute_ant_volume(parameter) for parameter in parameter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f'folder_name:{folder_name}')\n",
    "logging.info(f'morphology_nums:{morphology_nums}')\n",
    "logging.info(f'rewardfunc_nums:{rewardfunc_nums}')\n",
    "logging.info(f'parameter_list:{parameter_list}')\n",
    "logging.info(f'morphology_list:{morphology_list}')\n",
    "logging.info(f'material_list:{material_list}')\n",
    "logging.info(f'_________________________________enter coarse optimization stage_________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 results/Div_m25_r5/env/GPTrewardfunc_0.py\n",
      "24 results/Div_m25_r5/assets/GPTAnt_24.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "1 results/Div_m25_r5/env/GPTrewardfunc_1.py\n",
      "24 results/Div_m25_r5/assets/GPTAnt_24.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "2 results/Div_m25_r5/env/GPTrewardfunc_2.py\n",
      "24 results/Div_m25_r5/assets/GPTAnt_24.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "3 results/Div_m25_r5/env/GPTrewardfunc_3.py\n",
      "24 results/Div_m25_r5/assets/GPTAnt_24.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "4 results/Div_m25_r5/env/GPTrewardfunc_4.py\n",
      "24 results/Div_m25_r5/assets/GPTAnt_24.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "5 results/Div_m25_r5/env/GPTrewardfunc_5.py\n",
      "24 results/Div_m25_r5/assets/GPTAnt_24.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i, rewardfunc in enumerate(rewardfunc_list):\n",
    "    for j, morphology in enumerate(morphology_list):\n",
    "        # if i not in [0] or j not in [12]:\n",
    "        #     continue\n",
    "        if j not in [24]:\n",
    "            continue\n",
    "        # if i not in [0, 1,2,3,4]:\n",
    "        #     continue\n",
    "        print(i, rewardfunc)\n",
    "        print(j, morphology)\n",
    "        shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(rewardfunc, \"GPTrewardfunc.py\")         \n",
    "\n",
    "        import GPTrewardfunc\n",
    "        importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "        from GPTrewardfunc import _get_rew\n",
    "        GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "        env_name = \"GPTAntEnv\"\n",
    "        model_path = Train(j,  i, folder_name, total_timesteps=5e5)\n",
    "        # model_path = f\"results/div2025-03-17_15-13-46/SAC_morphology{j}_rewardfunc{i}_500000.0steps\"\n",
    "        fitness, reward = Eva(model_path)\n",
    "        material = material_list[j]\n",
    "        efficiency = fitness/material\n",
    "        fitness_matrix[i][j] = fitness\n",
    "        efficiency_matrix[i][j] = efficiency\n",
    "        \n",
    "        logging.info(\"___________________finish coarse optimization_____________________\")\n",
    "        logging.info(f\"morphology: {j}, rewardfunc: {i}, material cost: {material} reward: {reward} fitness: {fitness} efficiency: {efficiency}\")\n",
    "\n",
    "        if fitness > best_fitness:\n",
    "            best_fitness = fitness\n",
    "            best_morphology = morphology\n",
    "            best_efficiency = efficiency\n",
    "            best_rewardfunc = rewardfunc\n",
    "            best_material = material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.12901472277564, 3.8950108978919857, 36.38857403994179,\n",
       "        304.4116553571402, 8.020361623253192, 2017.8516590285078,\n",
       "        1.2415581186726266, 96.21844827615774, 6.819354811214885,\n",
       "        17.44389647393199, 2.961451393360138, 48.904232779343815,\n",
       "        2.677638986129011, 6.792677716341557, 0.1082644939638393,\n",
       "        178.92171372457375, 0.5305996358522651, 2777.3886334384847,\n",
       "        429.7795806064214, -3.9330932345003826, 9.731541015144876,\n",
       "        110.05889487574825, 1.3136332680205476, 79.87286091934128,\n",
       "        991.6757041414498, 15.258911788833924],\n",
       "       [63.24032185908237, 7.058282876583571, 29.60644096432709,\n",
       "        196.65112945445128, 10.592262912674121, 2328.240901485146,\n",
       "        14.249609494065261, 91.78182496369733, 10.319916115600542,\n",
       "        12.874172232006638, 4.474624645915348, 80.88527697953651,\n",
       "        14.273630365535217, 15.933260766873094, 0.4474799031617528,\n",
       "        195.83407065661854, 4.3861795690295775, 3859.6762180864503,\n",
       "        553.0126300970579, -3.9431994809443767, 23.35683214655262,\n",
       "        108.76369206964385, 1.5505922045510778, 164.08396086658882,\n",
       "        3142.5781115169507, 16.029479624540965],\n",
       "       [64.43158787667042, 8.141649213230023, 34.03087821710788,\n",
       "        239.54529125822526, 14.986610488684708, 2909.1893716011145,\n",
       "        2.1217889315831404, 96.52944382960696, 13.438467711297411,\n",
       "        16.942951352754896, 3.522105055618922, 40.78230525373979,\n",
       "        7.147495893693545, -0.7721329475976957, 0.15241059365665097,\n",
       "        137.75465803123544, 5.304310064373623, 2629.51604113934,\n",
       "        815.8128430519389, -3.9466165400134794, 24.732374620766524,\n",
       "        44.57757014440089, 1.0228895460372942, 217.98712766789797,\n",
       "        1864.959214669196, 18.03633557101774],\n",
       "       [72.84319575651284, 12.491211315362388, 25.668535935748118,\n",
       "        151.76169703159263, 11.29488863559477, 4846.415432733164,\n",
       "        8.879156521089088, 78.3430023117369, 20.23957107441512,\n",
       "        5.283127328548385, 6.675908657060871, 86.84222482929549,\n",
       "        4.323941019522104, -8.155150851430042, 0.2709330317808642,\n",
       "        242.33690702783886, 1.1519432201609145, 3927.5924351284716,\n",
       "        776.8823685360268, -3.9006578615629777, 13.468037088493993,\n",
       "        51.47757253378492, 1.2405526954218664, 90.24069454088942,\n",
       "        2662.2264439903734, 17.47779279594377],\n",
       "       [49.57189495703011, 3.798243661884369, 26.097717711919106,\n",
       "        328.0945829646423, 4.146449930076461, 2983.9363184163567,\n",
       "        14.596416580989677, 100.24855867883234, 15.567627652266964,\n",
       "        5.166609489553714, 5.364329426378386, 36.79022401302955,\n",
       "        4.897485971948941, 25.99373528155112, 0.43409586104502706,\n",
       "        141.97469571998894, 0.22459944692637557, 2364.93178435668,\n",
       "        197.7430958007017, -3.987572097722751, 12.964421558578492,\n",
       "        105.83639972826796, 1.2150169196799276, 100.11125346604726,\n",
       "        6537.446107236452, 15.376241750159544],\n",
       "       [65.76430696628158, 9.332153046637826, 27.49097298587031,\n",
       "        228.2097970494801, 13.050052751227259, 1552.2917121961602,\n",
       "        0.9104570123156992, 48.89612689745986, 7.034496743763769,\n",
       "        7.4182394798083555, 4.6163442674044255, 54.76806618536609,\n",
       "        5.081310178591359, 50.756260826484144, 0.3998242407655389,\n",
       "        78.19442201715779, 3.4217758073483178, 3026.527223369712,\n",
       "        379.47465765581677, -4.014168091877938, 21.420420550229224,\n",
       "        60.15076306164326, 1.1030938076895507, 70.36574217207183,\n",
       "        2912.473029236097, 8.679565785234878]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficiency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.370409798250126, 0.2694031161199691, 1.2053973361422903,\n",
       "        10.31310120379217, 2.428685533666429, 18.40640581562191,\n",
       "        0.7657339535055587, 3.7940199974245616, 1.2484189790466274,\n",
       "        6.7439026027340105, 3.1544368738885797, 0.7976274302844721,\n",
       "        1.4960668379240454, 0.1361814876394193, 0.008067331072490797,\n",
       "        6.465820806363407, 0.12091377508465335, 5.012471511630434,\n",
       "        3.0494048294076372, -2.7487032997006002, 1.170796293860529,\n",
       "        29.766605852576514, 0.12986853889942698, 3.1823596808905643,\n",
       "        5.333683749926142, 2.779807766447567],\n",
       "       [7.548194022492659, 0.4881946292979448, 0.9807343654599262,\n",
       "        6.6623040353839755, 3.207495735630992, 21.237709262482284,\n",
       "        8.788480901294038, 3.619078103535323, 1.8892665798378692,\n",
       "        4.977223050665417, 4.7662173390834734, 1.319237864667737,\n",
       "        7.975050093490848, 0.31943443289816575, 0.03334397451021867,\n",
       "        7.076994637976672, 0.9995286352556212, 6.965721993081067,\n",
       "        3.923777352478973, -2.7557662070083957, 2.8100475013102706,\n",
       "        29.41630439378042, 0.15329479614758057, 6.537567020041629,\n",
       "        16.902216860080227, 2.920186745231664],\n",
       "       [7.690380317072141, 0.5631269657260631, 1.1272969890069966,\n",
       "        8.115506709950298, 4.5381699482271705, 26.53699538744324,\n",
       "        1.3086184228109425, 3.8062829612328115, 2.460179680414685,\n",
       "        6.550234570389192, 3.751626005432334, 0.6651588930428338,\n",
       "        3.9934926389057277, -0.015479935579204317, 0.01135687863089945,\n",
       "        4.978137731471474, 1.2087534758156344, 4.745599548763368,\n",
       "        5.788417448742299, -2.758154271816045, 2.975538252297298,\n",
       "        12.05648086737562, 0.10112500500199245, 8.68522096315044,\n",
       "        10.030600342445501, 3.2857877673333813],\n",
       "       [8.694367116185184, 0.8639696629072092, 0.8502884670792923,\n",
       "        5.141503989096024, 3.420261320151747, 44.20795196061497,\n",
       "        5.476241123498292, 3.089167646685705, 3.705257367677796,\n",
       "        2.042484957120455, 7.110949881453576, 1.416395610239175,\n",
       "        2.4158987832031924, -0.163496727100688, 0.02018858063087549,\n",
       "        8.757500601757037, 0.2625064060006432, 7.088293281449661,\n",
       "        5.512194979465266, -2.7260353355043763, 1.6203320608981857,\n",
       "        13.922660350083554, 0.12264364027941445, 3.595443365581854,\n",
       "        14.318666741188752, 3.1840346695023825],\n",
       "       [5.916767502101989, 0.2627100937890489, 0.8645054179592436,\n",
       "        11.115450341612473, 1.255607095327473, 27.21882084790471,\n",
       "        9.002375005629885, 3.9529325524856374, 2.849964895192011,\n",
       "        1.9974385445350915, 5.7139004827812006, 0.6000480975032809,\n",
       "        2.736353328356418, 0.5211296174748321, 0.03234666232696633,\n",
       "        5.130640225012216, 0.05118203099814166, 4.268093076107038,\n",
       "        1.4030418812960872, -2.786776699484189, 1.559742356242155,\n",
       "        28.624586855280924, 0.12011911995399198, 3.988714226168625,\n",
       "        35.16136366209836, 2.8011824714228344],\n",
       "       [7.849450068302702, 0.6454695960500014, 0.910657987552753,\n",
       "        7.731473783114316, 3.9517512824607057, 14.159668809681037,\n",
       "        0.5615265504306113, 1.9280386097386324, 1.2878050029767925,\n",
       "        2.8679306031393277, 4.917172239366828, 0.8932664804330582,\n",
       "        2.839060713851651, 1.0175756005229313, 0.02979291181225311,\n",
       "        2.8257672604141844, 0.779758979094023, 5.462102531734381,\n",
       "        2.692477506866849, -2.8053637231153403, 2.577078897793551,\n",
       "        16.268417539618518, 0.1090541664566055, 2.803569300346892,\n",
       "        15.664606890398295, 1.5812087200637983]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print coarse optimization info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f'_________________________________end coarse optimization stage_________________________________')\n",
    "logging.info(f\"Stage1: Final best morphology: {best_morphology}, Fitness: {best_fitness}, best_efficiency: {best_efficiency}, best reward function: {best_rewardfunc}, Material cost: {best_material}, Reward: {best_reward}\")\n",
    "logging.info(f'folder_name:{folder_name}')\n",
    "logging.info(f'parameter_list:{parameter_list}')\n",
    "logging.info(f'fitness_matrix:{fitness_matrix}')\n",
    "logging.info(f'efficiency_matrix:{efficiency_matrix}')\n",
    "logging.info(f'_________________________________enter fine optimization stage_________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均值： 398.6031807645969\n",
      "标准差： 1022.3979367550053\n"
     ]
    }
   ],
   "source": [
    "efficiency_matrix = np.array([[70.12901472277564, 3.8950108978919857, 36.38857403994179,\n",
    "        304.4116553571402, 8.020361623253192, 2017.8516590285078,\n",
    "        1.2415581186726266, 96.21844827615774, 6.819354811214885,\n",
    "        17.44389647393199, 2.961451393360138, 48.904232779343815,\n",
    "        2.677638986129011, 6.792677716341557, 0.1082644939638393,\n",
    "        178.92171372457375, 0.5305996358522651, 2777.3886334384847,\n",
    "        429.7795806064214, -3.9330932345003826, 9.731541015144876,\n",
    "        110.05889487574825, 1.3136332680205476, 79.87286091934128,\n",
    "        991.6757041414498, 15.258911788833924],\n",
    "       [63.24032185908237, 7.058282876583571, 29.60644096432709,\n",
    "        196.65112945445128, 10.592262912674121, 2328.240901485146,\n",
    "        14.249609494065261, 91.78182496369733, 10.319916115600542,\n",
    "        12.874172232006638, 4.474624645915348, 80.88527697953651,\n",
    "        14.273630365535217, 15.933260766873094, 0.4474799031617528,\n",
    "        195.83407065661854, 4.3861795690295775, 3859.6762180864503,\n",
    "        553.0126300970579, -3.9431994809443767, 23.35683214655262,\n",
    "        108.76369206964385, 1.5505922045510778, 164.08396086658882,\n",
    "        3142.5781115169507, 16.029479624540965],\n",
    "       [64.43158787667042, 8.141649213230023, 34.03087821710788,\n",
    "        239.54529125822526, 14.986610488684708, 2909.1893716011145,\n",
    "        2.1217889315831404, 96.52944382960696, 13.438467711297411,\n",
    "        16.942951352754896, 3.522105055618922, 40.78230525373979,\n",
    "        7.147495893693545, -0.7721329475976957, 0.15241059365665097,\n",
    "        137.75465803123544, 5.304310064373623, 2629.51604113934,\n",
    "        815.8128430519389, -3.9466165400134794, 24.732374620766524,\n",
    "        44.57757014440089, 1.0228895460372942, 217.98712766789797,\n",
    "        1864.959214669196, 18.03633557101774],\n",
    "       [72.84319575651284, 12.491211315362388, 25.668535935748118,\n",
    "        151.76169703159263, 11.29488863559477, 4846.415432733164,\n",
    "        8.879156521089088, 78.3430023117369, 20.23957107441512,\n",
    "        5.283127328548385, 6.675908657060871, 86.84222482929549,\n",
    "        4.323941019522104, -8.155150851430042, 0.2709330317808642,\n",
    "        242.33690702783886, 1.1519432201609145, 3927.5924351284716,\n",
    "        776.8823685360268, -3.9006578615629777, 13.468037088493993,\n",
    "        51.47757253378492, 1.2405526954218664, 90.24069454088942,\n",
    "        2662.2264439903734, 17.47779279594377],\n",
    "       [49.57189495703011, 3.798243661884369, 26.097717711919106,\n",
    "        328.0945829646423, 4.146449930076461, 2983.9363184163567,\n",
    "        14.596416580989677, 100.24855867883234, 15.567627652266964,\n",
    "        5.166609489553714, 5.364329426378386, 36.79022401302955,\n",
    "        4.897485971948941, 25.99373528155112, 0.43409586104502706,\n",
    "        141.97469571998894, 0.22459944692637557, 2364.93178435668,\n",
    "        197.7430958007017, -3.987572097722751, 12.964421558578492,\n",
    "        105.83639972826796, 1.2150169196799276, 100.11125346604726,\n",
    "        6537.446107236452, 15.376241750159544],\n",
    "       [65.76430696628158, 9.332153046637826, 27.49097298587031,\n",
    "        228.2097970494801, 13.050052751227259, 1552.2917121961602,\n",
    "        0.9104570123156992, 48.89612689745986, 7.034496743763769,\n",
    "        7.4182394798083555, 4.6163442674044255, 54.76806618536609,\n",
    "        5.081310178591359, 50.756260826484144, 0.3998242407655389,\n",
    "        78.19442201715779, 3.4217758073483178, 3026.527223369712,\n",
    "        379.47465765581677, -4.014168091877938, 21.420420550229224,\n",
    "        60.15076306164326, 1.1030938076895507, 70.36574217207183,\n",
    "        2912.473029236097, 8.679565785234878]], dtype=object)\n",
    "\n",
    "mean = np.mean(efficiency_matrix)\n",
    "\n",
    "std = np.std(efficiency_matrix)\n",
    "\n",
    "print(\"平均值：\", mean)\n",
    "print(\"标准差：\", std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitness_matrix = np.array([[8.370409798250126, 0.2694031161199691, 1.2053973361422903,\n",
    "        10.31310120379217, 2.428685533666429, 18.40640581562191,\n",
    "        0.7657339535055587, 3.7940199974245616, 1.2484189790466274,\n",
    "        6.7439026027340105, 3.1544368738885797, 0.7976274302844721,\n",
    "        1.4960668379240454, 0.1361814876394193, 0.008067331072490797,\n",
    "        6.465820806363407, 0.12091377508465335, 5.012471511630434,\n",
    "        3.0494048294076372, -2.7487032997006002, 1.170796293860529,\n",
    "        29.766605852576514, 0.12986853889942698, 3.1823596808905643,\n",
    "        5.333683749926142, 2.779807766447567],\n",
    "       [7.548194022492659, 0.4881946292979448, 0.9807343654599262,\n",
    "        6.6623040353839755, 3.207495735630992, 21.237709262482284,\n",
    "        8.788480901294038, 3.619078103535323, 1.8892665798378692,\n",
    "        4.977223050665417, 4.7662173390834734, 1.319237864667737,\n",
    "        7.975050093490848, 0.31943443289816575, 0.03334397451021867,\n",
    "        7.076994637976672, 0.9995286352556212, 6.965721993081067,\n",
    "        3.923777352478973, -2.7557662070083957, 2.8100475013102706,\n",
    "        29.41630439378042, 0.15329479614758057, 6.537567020041629,\n",
    "        16.902216860080227, 2.920186745231664],\n",
    "       [7.690380317072141, 0.5631269657260631, 1.1272969890069966,\n",
    "        8.115506709950298, 4.5381699482271705, 26.53699538744324,\n",
    "        1.3086184228109425, 3.8062829612328115, 2.460179680414685,\n",
    "        6.550234570389192, 3.751626005432334, 0.6651588930428338,\n",
    "        3.9934926389057277, -0.015479935579204317, 0.01135687863089945,\n",
    "        4.978137731471474, 1.2087534758156344, 4.745599548763368,\n",
    "        5.788417448742299, -2.758154271816045, 2.975538252297298,\n",
    "        12.05648086737562, 0.10112500500199245, 8.68522096315044,\n",
    "        10.030600342445501, 3.2857877673333813],\n",
    "       [8.694367116185184, 0.8639696629072092, 0.8502884670792923,\n",
    "        5.141503989096024, 3.420261320151747, 44.20795196061497,\n",
    "        5.476241123498292, 3.089167646685705, 3.705257367677796,\n",
    "        2.042484957120455, 7.110949881453576, 1.416395610239175,\n",
    "        2.4158987832031924, -0.163496727100688, 0.02018858063087549,\n",
    "        8.757500601757037, 0.2625064060006432, 7.088293281449661,\n",
    "        5.512194979465266, -2.7260353355043763, 1.6203320608981857,\n",
    "        13.922660350083554, 0.12264364027941445, 3.595443365581854,\n",
    "        14.318666741188752, 3.1840346695023825],\n",
    "       [5.916767502101989, 0.2627100937890489, 0.8645054179592436,\n",
    "        11.115450341612473, 1.255607095327473, 27.21882084790471,\n",
    "        9.002375005629885, 3.9529325524856374, 2.849964895192011,\n",
    "        1.9974385445350915, 5.7139004827812006, 0.6000480975032809,\n",
    "        2.736353328356418, 0.5211296174748321, 0.03234666232696633,\n",
    "        5.130640225012216, 0.05118203099814166, 4.268093076107038,\n",
    "        1.4030418812960872, -2.786776699484189, 1.559742356242155,\n",
    "        28.624586855280924, 0.12011911995399198, 3.988714226168625,\n",
    "        35.16136366209836, 2.8011824714228344],\n",
    "       [7.849450068302702, 0.6454695960500014, 0.910657987552753,\n",
    "        7.731473783114316, 3.9517512824607057, 14.159668809681037,\n",
    "        0.5615265504306113, 1.9280386097386324, 1.2878050029767925,\n",
    "        2.8679306031393277, 4.917172239366828, 0.8932664804330582,\n",
    "        2.839060713851651, 1.0175756005229313, 0.02979291181225311,\n",
    "        2.8257672604141844, 0.779758979094023, 5.462102531734381,\n",
    "        2.692477506866849, -2.8053637231153403, 2.577078897793551,\n",
    "        16.268417539618518, 0.1090541664566055, 2.803569300346892,\n",
    "        15.664606890398295, 1.5812087200637983]], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configuration of fine optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "efficiency_matrix_select = efficiency_matrix[:4][:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 获取矩阵中所有非 None 的值和它们的坐标\n",
    "all_values_with_coords = []\n",
    "for i in range(len(efficiency_matrix_select)):\n",
    "    for j in range(len(efficiency_matrix_select[0])):\n",
    "        value = efficiency_matrix_select[i][j]\n",
    "        if value is not None:\n",
    "            all_values_with_coords.append(((i, j), value))\n",
    "\n",
    "# 按值降序排序\n",
    "sorted_values = sorted(all_values_with_coords, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 计算前 20% 的数量（至少选1个）\n",
    "top_k = max(1, int(len(sorted_values) * 0.1))\n",
    "# 取前 20% 个坐标\n",
    "efficiency_coarse_best = [coord for coord, val in sorted_values[:top_k]]\n",
    "\n",
    "logging.info(f\"fitness_coarse_best {efficiency_coarse_best}\")\n",
    "logging.info(f\"fitness_coarse_best values {sorted_values[:top_k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 5),\n",
       " (3, 17),\n",
       " (1, 17),\n",
       " (1, 24),\n",
       " (2, 5),\n",
       " (0, 17),\n",
       " (3, 24),\n",
       " (2, 17),\n",
       " (1, 5),\n",
       " (0, 5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_best = efficiency_coarse_best\n",
    "coarse_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter fine optimization stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: [0.1, 0.3, 0.2, 0.2, 0.3, 0.15, 0.1, 0.02, 0.02, 0.02]\n",
      "ChatCompletion(id='chatcmpl-BSU69FFiqcLgJO6QfZ49hDzo5sAb5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.019, 0.019, 0.019],\\n  \"desciption\": \"Optimizing the leg geometries and weights to maximize walking distance while maintaining low material costs and compatibility with control gears.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746128581, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=87, prompt_tokens=4138, total_tokens=4225, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.019, 0.019, 0.019]\n",
      "Successfully saved GPTAnt_refine_3_5_0.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/robodesign/lib/python3.8/site-packages/stable_baselines3/common/save_util.py:284: UserWarning: Path 'results/Div_m25_r5/fine' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.019, 0.019, 0.019]\n",
      "ChatCompletion(id='chatcmpl-BSUCX8FYtSJ4WCiiVJp7VpWAiRrkH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Rewarding forward movement with higher importance to velocity\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # General health reward for remaining upright and within healthy z-range\\n    healthy_reward = self.healthy_reward\\n    \\n    # Increasing total reward by emphasizing the velocity component\\n    rewards = forward_reward + healthy_reward\\n    \\n    # Control cost: minimize the squared sum of action to promote efficiency\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Contact cost: penalize contact forces to encourage smooth movement without harsh impacts\\n    contact_cost = self.contact_cost\\n    \\n    # Calculate total cost considering control usage and contacts\\n    costs = ctrl_cost + contact_cost\\n    \\n    # Calculate the total reward by considering all rewards and costs\\n    reward = rewards - costs\\n    \\n    # Reward info for possible debugging and monitoring\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward\\n    }\\n\\n    return reward, reward_info    \\n```\\nThis reward function captures both the dynamic performance (x_velocity) and energy efficiency (control costs), along with survivability and contact management. It strikes a balance between encouraging fast forward movement and minimizing unnecessary torque and harsh ground interactions.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746128977, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=282, prompt_tokens=1931, total_tokens=2213, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.019, 0.019, 0.019]\n",
      "ChatCompletion(id='chatcmpl-BSUJ27COsjBnFkTmj1Z5WAWaB8iJX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.095, 0.32, 0.23, 0.23, 0.32, 0.17, 0.12, 0.018, 0.018, 0.018],\\n  \"description\": \"Optimized smaller geometry for reduced material cost, focused on enhancing leg and ankle dimensions for improved locomotion without significantly increasing cost, ensuring maximum distance per unit of material used.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746129380, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=95, prompt_tokens=4138, total_tokens=4233, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.095, 0.32, 0.23, 0.23, 0.32, 0.17, 0.12, 0.018, 0.018, 0.018]\n",
      "Successfully saved GPTAnt_refine_3_5_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.095, 0.32, 0.23, 0.23, 0.32, 0.17, 0.12, 0.018, 0.018, 0.018]\n",
      "params: [0.05, 0.4, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSUPOpmJH2VSa0SB8qocQANtdjoWn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.06, 0.42, 0.22, 0.27, 0.22, 0.17, 0.17, 0.012, 0.012, 0.012],\\n  \"description\": \"Optimized design with slightly larger dimensions and minimal increase in capsule sizes, ensuring improved mobility with a minimal material cost increase.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746129774, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=85, prompt_tokens=4138, total_tokens=4223, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.06, 0.42, 0.22, 0.27, 0.22, 0.17, 0.17, 0.012, 0.012, 0.012]\n",
      "Successfully saved GPTAnt_refine_3_17_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.06, 0.42, 0.22, 0.27, 0.22, 0.17, 0.17, 0.012, 0.012, 0.012]\n",
      "ChatCompletion(id='chatcmpl-BSUVhMjkSITEjOoQUgNAjbHfJyerh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward for moving forward directly proportional to x_velocity\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Constant reward for keeping the robot healthy (i.e., within the specified z range)\\n    healthy_reward = self.healthy_reward\\n    \\n    # Sum of forward and healthy rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Control cost penalizes the square of actions to prevent erratic movements\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Contact cost penalizes the square of contact forces to prevent too much scraping or collisions\\n    contact_cost = self.contact_cost\\n    \\n    # Total costs are the sum of control and contact costs\\n    costs = ctrl_cost + contact_cost\\n\\n    # Net reward is total rewards minus total costs\\n    reward = rewards - costs\\n\\n    # Information dictionary to track individual components of the reward\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function incentivizes the agent to drive forward as quickly as possible while maintaining stability and minimizing unnecessary movements and physical contacts. The reward for forward motion encourages acceleration in the desired direction, while penalties for control and contact help ensure efficient, smooth, and safe movements. The survival reward ensures that the robot maintains a healthy posture, preventing the reward exploitations that could arise from unnatural poses.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746130165, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=321, prompt_tokens=1931, total_tokens=2252, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.06, 0.42, 0.22, 0.27, 0.22, 0.17, 0.17, 0.012, 0.012, 0.012]\n",
      "ChatCompletion(id='chatcmpl-BSUc3rkk6sS4VqZOJ0wNDkgtntSfm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.08, 0.4, 0.3, 0.3, 0.2, 0.2, 0.16, 0.01, 0.011, 0.012],\\n  \"desciption\": \"Efficiently optimized for improved walking distance to material cost by reducing leg and ankle capsule sizes while maintaining sufficient joint range and control\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746130559, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=89, prompt_tokens=4138, total_tokens=4227, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.08, 0.4, 0.3, 0.3, 0.2, 0.2, 0.16, 0.01, 0.011, 0.012]\n",
      "Successfully saved GPTAnt_refine_3_17_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.08, 0.4, 0.3, 0.3, 0.2, 0.2, 0.16, 0.01, 0.011, 0.012]\n",
      "params: [0.05, 0.4, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSUiPbeb5zpwiqBe6sj5ZsIoQmtVU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.04, 0.41, 0.21, 0.26, 0.21, 0.16, 0.16, 0.01, 0.01, 0.01],\\n  \"desciption\": \"Optimal small material usage with extended leg dimensions to enhance locomotion efficiency and fitness.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746130953, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=80, prompt_tokens=4139, total_tokens=4219, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.04, 0.41, 0.21, 0.26, 0.21, 0.16, 0.16, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_1_17_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.04, 0.41, 0.21, 0.26, 0.21, 0.16, 0.16, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSUo27PGQZQEIB1KdohtttjtkqjSa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Calculate the forward reward related to the x_velocity\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Compute reward for the robot being \\'healthy\\' (not falling over)\\n    healthy_reward = self.healthy_reward\\n    \\n    # Sum the healthy and forward rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Compute the control cost which penalizes large actions\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Compute the cost related to contact forces, penalizing excessive forces\\n    contact_cost = self.contact_cost\\n    \\n    # Sum all costs\\n    costs = ctrl_cost + contact_cost\\n\\n    # Total reward is the difference between rewards and costs\\n    reward = rewards - costs\\n\\n    # Dictionary with the breakdown of each reward component\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746131302, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=226, prompt_tokens=1931, total_tokens=2157, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.04, 0.41, 0.21, 0.26, 0.21, 0.16, 0.16, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSUtp0jjrJQ9Z3njARETIeo4bqS2x', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008],\\n  \"desciption\": \"Optimized for minimized material cost with efficient limb functionality to increase walking distance\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746131661, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=78, prompt_tokens=4139, total_tokens=4217, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008]\n",
      "Successfully saved GPTAnt_refine_1_17_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008]\n",
      "ChatCompletion(id='chatcmpl-BSV06o4oCmS04V20C1yS6bb1EzSyV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward for moving forward in the x-direction, scaled by the forward_reward_weight\\n    forward_reward = x_velocity * self._forward_reward_weight\\n\\n    # Reward for staying healthy (being within a certain z range); 1 if healthy, 0 otherwise\\n    healthy_reward = self.healthy_reward\\n\\n    # Sum of the rewards for forward movement and being healthy\\n    rewards = forward_reward + healthy_reward\\n\\n    # Cost imposed due to the control effort (squared magnitude of action vector scaled by ctrl_cost_weight)\\n    ctrl_cost = self.control_cost(action)\\n\\n    # Cost based on the magnitude of the contact forces, clipped within a predefined range, scaled by contact_cost_weight\\n    contact_cost = self.contact_cost\\n\\n    # Total cost is the sum of control cost and contact cost\\n    costs = ctrl_cost + contact_cost\\n\\n    # Total reward is the sum of positive rewards minus the costs\\n    reward = rewards - costs\\n\\n    # Information about each individual component of the reward, useful for debugging and analysis\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function aims to optimize the ant\\'s forward speed while minimizing control and contact costs. It encourages forward movement by incrementally rewarding x-axis velocity and maintaining robot health by rewarding being within a healthy Z-range. Control and contact costs penalize excessive use of actuator effort and large contact forces, potentially leading to more efficient and stable locomotion.\\n', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746132050, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=347, prompt_tokens=1931, total_tokens=2278, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008]\n",
      "ChatCompletion(id='chatcmpl-BSV6QQoVB6gIlreomrleDEgV8GS53', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008],\\n  \"description\": \"Optimized design focusing on minimal material costs and streamlined leg configurations to maximize walking distance per cost.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746132442, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=80, prompt_tokens=4139, total_tokens=4219, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008]\n",
      "Successfully saved GPTAnt_refine_1_17_4.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008]\n",
      "params: [0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015]\n",
      "ChatCompletion(id='chatcmpl-BSVCJ6sV36iCpFeyZ5wqoa9WA2Ozo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.07, 0.33, 0.25, 0.17, 0.03, 0.13, 0.04, 0.018, 0.013, 0.013],\\n  \"desciption\": \"Optimized for maximum efficiency by balancing lightweight design and effective limb articulation to enhance walking distance versus material cost ratio.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746132807, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=86, prompt_tokens=4139, total_tokens=4225, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.07, 0.33, 0.25, 0.17, 0.03, 0.13, 0.04, 0.018, 0.013, 0.013]\n",
      "Successfully saved GPTAnt_refine_1_24_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.07, 0.33, 0.25, 0.17, 0.03, 0.13, 0.04, 0.018, 0.013, 0.013]\n",
      "ChatCompletion(id='chatcmpl-BSVIdXkFWaH1f55xBQvsaU3j434ag', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Encourage forward movement by assigning high weight to x_velocity\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Include the health state reward, which promotes the Ant to stay \"healthy\" (upright and within the z-range limits)\\n    healthy_reward = self.healthy_reward\\n    \\n    # Calculate total rewards aggregation\\n    rewards = forward_reward + healthy_reward\\n    \\n    # Compute control cost, penalizing large actions to ensure smooth movements\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Compute contact cost, penalizing excessive contact forces to avoid erratic behaviors\\n    contact_cost = self.contact_cost\\n    \\n    # Calculate total costs from control and contact\\n    costs = ctrl_cost + contact_cost\\n    \\n    # The total reward for the agent after removing costs from the total gains\\n    reward = rewards - costs\\n    \\n    # Return reward and individual components in the reward info dictionary for detailed performance tracking\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n    \\n    return reward, reward_info\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746133199, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=256, prompt_tokens=1931, total_tokens=2187, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.07, 0.33, 0.25, 0.17, 0.03, 0.13, 0.04, 0.018, 0.013, 0.013]\n",
      "ChatCompletion(id='chatcmpl-BSVP6isZBylrxfXmMousi5ypV3PHq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.06, 0.34, 0.24, 0.16, 0.03, 0.12, 0.04, 0.017, 0.012, 0.012],\\n  \"desciption\": \"Optimized robot design with streamlined leg and ankle lengths, minimal capsule sizes for reduced material cost while maintaining efficient mobility.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746133600, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=86, prompt_tokens=4139, total_tokens=4225, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.06, 0.34, 0.24, 0.16, 0.03, 0.12, 0.04, 0.017, 0.012, 0.012]\n",
      "Successfully saved GPTAnt_refine_1_24_1.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.06, 0.34, 0.24, 0.16, 0.03, 0.12, 0.04, 0.017, 0.012, 0.012]\n",
      "ChatCompletion(id='chatcmpl-BSVVPlKQHvWnuyewSLBBpJYzKluqZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward for moving forward: the faster the x_velocity, the higher the reward\\n    forward_reward = x_velocity * self._forward_reward_weight\\n\\n    # Add a constant reward for staying healthy (i.e., not falling down or going out of allowed z range)\\n    healthy_reward = self.healthy_reward\\n\\n    # Total positive rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Control cost: penalize large actions to enforce energy efficiency\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Contact cost: penalize excessive contact force to encourage smooth motion\\n    contact_cost = self.contact_cost\\n    \\n    # Sum up all the costs\\n    costs = ctrl_cost + contact_cost\\n\\n    # Total reward combining all rewards and costs\\n    reward = rewards - costs\\n\\n    # Dictionary to track individual components for analysis and debugging\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function implementation facilitates the Ant robot to optimize its speed movement forward while balancing energy efficiency and smooth motion. It also guarantees the robot stays \\'healthy\\', thus preventing it from executing physically implausible or damaging maneuvers.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746133991, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=284, prompt_tokens=1931, total_tokens=2215, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.06, 0.34, 0.24, 0.16, 0.03, 0.12, 0.04, 0.017, 0.012, 0.012]\n",
      "ChatCompletion(id='chatcmpl-BSVbmFN9FjJoJwVcWMX8DBhCsawrw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.35, 0.25, 0.17, 0.02, 0.13, 0.05, 0.015, 0.01, 0.01],\\n  \"description\": \"Optimized for material efficiency and enhanced locomotion, focusing on minimal leg and joint size while ensuring sufficient reach and flexibility.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746134386, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=85, prompt_tokens=4139, total_tokens=4224, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.35, 0.25, 0.17, 0.02, 0.13, 0.05, 0.015, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_1_24_3.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.17, 0.02, 0.13, 0.05, 0.015, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSVi79JglXmDXflaxu1PRYro25x78', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward component for moving forward along the x-axis, emphasizing speed\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Reward for keeping the agent \\'healthy\\', i.e., within a defined z-axis range\\n    healthy_reward = self.healthy_reward\\n    \\n    # Sum of positive reward components\\n    rewards = forward_reward + healthy_reward\\n\\n    # Incremental cost penalizing the magnitude of actions to prevent excessive torque application\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Incremental cost related to the forces experienced during contact, to prevent high impacts or crashes\\n    contact_cost = self.contact_cost\\n    \\n    # Sum of cost components\\n    costs = ctrl_cost + contact_cost\\n\\n    # Calculate total reward by subtracting costs from the rewards\\n    reward = rewards - costs\\n\\n    # Dictionary containing detailed break-up of the reward for better interpretation and debugging\\n    reward_info = {\\n        \"reward_forward\": forward_reward,  # Component of reward for forward movement\\n        \"reward_ctrl\": -ctrl_cost,         # Cost due to control usage, negative as it\\'s a penalty\\n        \"reward_contact\": -contact_cost,   # Cost due to contact forces, negative as it\\'s a penalty\\n        \"reward_survive\": healthy_reward   # Reward for surviving, i.e., staying within healthy parameters\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function formulation incentivizes the ant agent to move as fast as possible in the forward direction (maximizing `x_velocity`), while balancing the control energy used (minimizing `action` magnitude) and maintaining its operational health by avoiding unhealthy states and minimizing collision impacts. The function provides a comprehensive breakdown of the reward components in the `reward_info` dictionary, aiding in transparency and tuning during training.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746134779, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=385, prompt_tokens=1931, total_tokens=2316, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.17, 0.02, 0.13, 0.05, 0.015, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSVoTotiSIjthf3cJEEqsUXvygDUz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.4, 0.25, 0.2, 0.02, 0.15, 0.1, 0.01, 0.01, 0.01],\\n  \"description\": \"Optimized lightweight design with increased leg leverage for enhanced walking distance, while minimizing material cost\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746135173, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=79, prompt_tokens=4139, total_tokens=4218, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.4, 0.25, 0.2, 0.02, 0.15, 0.1, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_1_24_4.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.4, 0.25, 0.2, 0.02, 0.15, 0.1, 0.01, 0.01, 0.01]\n",
      "params: [0.1, 0.3, 0.2, 0.2, 0.3, 0.15, 0.1, 0.02, 0.02, 0.02]\n",
      "ChatCompletion(id='chatcmpl-BSVuUwGjTm4KF1Xaa1mD40C36sLQY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.015, 0.015, 0.015],\\n  \"description\": \"Optimized for efficiency and cost, the design maintains a balance between larger mobility dimensions and minimizing material sizes to reduce costs while improving walking distance.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746135546, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=89, prompt_tokens=4139, total_tokens=4228, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.015, 0.015, 0.015]\n",
      "Successfully saved GPTAnt_refine_2_5_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.015, 0.015, 0.015]\n",
      "ChatCompletion(id='chatcmpl-BSW0xPonXcWwiXJOh1I2olwnYG5Mx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward for moving forward, the primary goal\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Bonus for keeping the ant healthy (not falling over and staying within a proper z range)\\n    healthy_reward = self.healthy_reward\\n    \\n    # Sum of rewards\\n    rewards = forward_reward + healthy_reward\\n    \\n    # Control costs (penalizing the magnitude of actions used, to encourage smooth and small movements)\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Contact costs (penalizing contact forces that are too high, suggesting collisions or unstable gait)\\n    contact_cost = self.contact_cost\\n    \\n    # Sum of costs\\n    costs = ctrl_cost + contact_cost\\n    \\n    # The final reward is the balance of rewards and costs\\n    reward = rewards - costs\\n    \\n    # Detailed reward components for debugging and analysis\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n    \\n    return reward, reward_info\\n```\\nThis reward function balances the main objectives of moving forward quickly (captured by `forward_reward`), maintaining the ant\\'s health (`healthy_reward`), and minimizing the control and contact costs (`ctrl_cost` and `contact_cost`). This setup should encourage the agent to learn efficient, stable, and quick movements.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746135947, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=306, prompt_tokens=1931, total_tokens=2237, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.09, 0.31, 0.21, 0.21, 0.31, 0.16, 0.11, 0.015, 0.015, 0.015]\n",
      "params: [0.05, 0.4, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSWDlI7mT8yuRRTThexxzCmBQli2P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.45, 0.25, 0.3, 0.25, 0.18, 0.18, 0.01, 0.01, 0.01],\\n  \"description\": \"Optimized lightweight and balanced leg dimensions with minimal actuator sizes to maximize fitness.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746136741, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=77, prompt_tokens=4141, total_tokens=4218, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.45, 0.25, 0.3, 0.25, 0.18, 0.18, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_0_17_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.45, 0.25, 0.3, 0.25, 0.18, 0.18, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSWJkzbDyY2Gz3jUctigC1Y7YHjjO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward for moving forward; faster movement gains more reward\\n    forward_reward = x_velocity * self._forward_reward_weight\\n\\n    # Healthy reward is granted if the robot maintains balance (health state)\\n    healthy_reward = self.healthy_reward\\n\\n    # Sum of healthy and forward movement rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Control cost penalizes excessive use of actions (torques)\\n    ctrl_cost = self.control_cost(action)\\n\\n    # Contact cost penalizes large contact forces which might indicate crashes or unhealthy contacts\\n    contact_cost = self.contact_cost\\n\\n    # Sum of control cost and contact cost\\n    costs = ctrl_cost + contact_cost\\n\\n    # Final reward calculation\\n    reward = rewards - costs\\n\\n    # Logging to help with debugging and understanding reward components\\n    reward_info = {\\n        'reward_forward': forward_reward,\\n        'reward_ctrl': -ctrl_cost,\\n        'reward_contact': -contact_cost,\\n        'reward_survive': healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function encourages forward motion by providing positive reward proportional to forward velocity, while controlling for excessive control commands and penalizing undesirable contacts. It aims to ensure the agent receives feedback that guides it toward efficient and safe movements, ultimately leading to learned behaviors that are effective in moving the modeled robot forward at an increased pace.\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746137112, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=293, prompt_tokens=1931, total_tokens=2224, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.45, 0.25, 0.3, 0.25, 0.18, 0.18, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSWPrshMOXW6VYQ12a7yDCyVGDDuy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.4, 0.25, 0.3, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01],\\n  \"description\": \"Optimized lightweight design focusing on minimal material usage with appropriately extended limb lengths to maximize walking distance relative to cost.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746137491, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=83, prompt_tokens=4141, total_tokens=4224, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.4, 0.25, 0.3, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_0_17_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.4, 0.25, 0.3, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01]\n",
      "params: [0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015]\n",
      "ChatCompletion(id='chatcmpl-BSWW1mDEliwIiJLS5J65nDa34QeSc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015],\\n  \"desciption\": \"Optimized design focused on minimal structure sizes and efficient material usage to maximize the walking distance over material cost ratio.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746137873, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=85, prompt_tokens=4138, total_tokens=4223, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015]\n",
      "Successfully saved GPTAnt_refine_3_24_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015]\n",
      "ChatCompletion(id='chatcmpl-BSWcLL0A5hjH99PBpuCDDS0vqxQVj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # The forward reward is computed as the velocity in the x-direction times the forward reward weight.\\n    # This emphasizes speed in the forward direction specifically.\\n    forward_reward = x_velocity * self._forward_reward_weight\\n\\n    # Healthy reward is given when the ant maintains its vertical stability within specified z bounds.\\n    healthy_reward = self.healthy_reward\\n\\n    # Sum of the rewards from moving forward and staying healthy.\\n    rewards = forward_reward + healthy_reward\\n\\n    # Control cost is calculated from the action. It penalizes large actions to encourage efficiency in the movement.\\n    ctrl_cost = self.control_cost(action)\\n\\n    # Contact cost captures the penalties from the contacts between the ant\\'s legs and the ground,\\n    # discouraging excessive force which may indicate slipping or hard impacts.\\n    contact_cost = self.contact_cost\\n\\n    # Sum of the cost related to control and contact forces.\\n    costs = ctrl_cost + contact_cost\\n\\n    # The total reward is the difference between the summed rewards and costs.\\n    # Using an exponential function to emphasize the importance of velocity and healthy state while penalizing large control and contact costs more sharply.\\n    total_reward = np.exp(rewards) - np.exp(costs)\\n\\n    # Provide detailed breakdown in the reward info for diagnostic and learning insights.\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n        \"exp_total_reward\": total_reward\\n    }\\n\\n    return total_reward, reward_info\\n```\\nThis reward function is built to strongly motivate forward movement and penalize energy inefficiency and unstable or harsh contacts. The use of the exponential function in the final reward calculation accentuates desirable behaviors (fast, stable movement) and sharply disincentivizes negative aspects (high control and contact costs), which should more effectively guide the learning process.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746138265, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=404, prompt_tokens=1931, total_tokens=2335, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.08, 0.32, 0.27, 0.16, 0.04, 0.14, 0.045, 0.02, 0.015, 0.015]\n",
      "ChatCompletion(id='chatcmpl-BSWir3AL9WOq4nhCxE2KFbYGXquCi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.09, 0.33, 0.28, 0.17, 0.03, 0.13, 0.05, 0.019, 0.012, 0.013],\\n  \"description\": \"Refinement of the best design by optimizing leg joints and reducing the mass distribution for enhanced efficiency and greater walking distance per material used.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746138669, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=87, prompt_tokens=4138, total_tokens=4225, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.09, 0.33, 0.28, 0.17, 0.03, 0.13, 0.05, 0.019, 0.012, 0.013]\n",
      "Successfully saved GPTAnt_refine_3_24_1.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.09, 0.33, 0.28, 0.17, 0.03, 0.13, 0.05, 0.019, 0.012, 0.013]\n",
      "ChatCompletion(id='chatcmpl-BSWpEEUbsHRrYaLxqPPdLOg29dG7l', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # The primary objective is to maximize the forward velocity along the x-axis\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Add a small reward for the agent just being \"alive\" to encourage staying within the constraints\\n    healthy_reward = self.healthy_reward\\n    \\n    # Control cost discourages excessive use of the actuators\\' torques\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Contact cost penalizes scenarios where the robot parts are hitting each other or the ground too hard\\n    contact_cost = self.contact_cost\\n    \\n    # Total reward is a combination of the forward reward and staying healthy,\\n    # while penalizing for high control and contact costs\\n    rewards = forward_reward + healthy_reward\\n    costs = ctrl_cost + contact_cost\\n    \\n    # Total calculated reward\\n    reward = rewards - costs\\n    \\n    # Form the detailed reward information to return for logging or debugging\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746139064, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=254, prompt_tokens=1931, total_tokens=2185, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.09, 0.33, 0.28, 0.17, 0.03, 0.13, 0.05, 0.019, 0.012, 0.013]\n",
      "ChatCompletion(id='chatcmpl-BSWvcGCLDIo9hMlprY254gwvUnkKl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.1, 0.35, 0.27, 0.18, 0.04, 0.14, 0.06, 0.02, 0.015, 0.015],\\n  \"desciption\": \"Optimized for reduced material cost while extending leg length and range for improved distance coverage.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746139460, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=80, prompt_tokens=4138, total_tokens=4218, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.1, 0.35, 0.27, 0.18, 0.04, 0.14, 0.06, 0.02, 0.015, 0.015]\n",
      "Successfully saved GPTAnt_refine_3_24_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.1, 0.35, 0.27, 0.18, 0.04, 0.14, 0.06, 0.02, 0.015, 0.015]\n",
      "params: [0.05, 0.4, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSX1x3OJg6poPWAFmwfjOOnP2aAM2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.35, 0.25, 0.2, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01],\\n  \"description\": \"Optimized lightweight design with minimal joint size to maximize walk distance while keeping material costs low.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746139853, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=79, prompt_tokens=4139, total_tokens=4218, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.35, 0.25, 0.2, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_2_17_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.2, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSX7k1GVFErGFkrWMzky2asqCubeG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Calculate the forward reward proportional to the x_velocity\\n    forward_reward = x_velocity * self._forward_reward_weight\\n\\n    # Get the healthy reward which encourages the ant to remain in a viable configuration\\n    healthy_reward = self.healthy_reward\\n\\n    # Sum the forward and healthy rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Calculate control cost as a function of the amount of torque applied at each joint\\n    ctrl_cost = self.control_cost(action)\\n\\n    # Calculate the contact cost based on the magnitude of forces experienced during contacts\\n    contact_cost = self.contact_cost\\n\\n    # Sum the control and contact costs\\n    costs = ctrl_cost + contact_cost\\n\\n    # The total reward is the difference between the sum of rewards and the sum of costs\\n    reward = rewards - costs\\n\\n    # Information about each component of the reward, helpful for debugging and understanding the model\\n    reward_info = {\\n        \"reward_forward\": forward_reward,   # Reward for moving forward\\n        \"reward_ctrl\": -ctrl_cost,          # Cost associated with the control effort\\n        \"reward_contact\": -contact_cost,    # Cost associated with contact forces\\n        \"reward_survive\": healthy_reward,   # Reward for staying in a healthy state\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function structure is designed to optimize the Ant robot\\'s ability to move forward rapidly while maintaining a configuration that prevents flipping over or excessive energy use. Feedback via `reward_info` helps in tuning and balancing rewards and costs.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746140212, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=330, prompt_tokens=1931, total_tokens=2261, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.2, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSXDtFIY2LfZ0DmHd6t6aUu0I6XGL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.1, 0.35, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01],\\n  \"desciption\": \"Optimized for high distance-to-material cost ratio with minimized geometric sizes for reduced weight and maximized leg lengths for improved stride efficiency.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746140593, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=89, prompt_tokens=4139, total_tokens=4228, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.1, 0.35, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_2_17_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.1, 0.35, 0.2, 0.25, 0.2, 0.15, 0.15, 0.01, 0.01, 0.01]\n",
      "params: [0.1, 0.3, 0.2, 0.2, 0.3, 0.15, 0.1, 0.02, 0.02, 0.02]\n",
      "ChatCompletion(id='chatcmpl-BSXKGTl2MTWT3jmQoYMb6zvlKf8Nu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.35, 0.25, 0.25, 0.35, 0.2, 0.15, 0.01, 0.01, 0.01],\\n  \"description\": \"Optimized for minimal material cost while ensuring adequate limb length for effective locomotion, using smaller joint sizes for reduced expenses and improved fitness.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746140988, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=88, prompt_tokens=4139, total_tokens=4227, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.35, 0.25, 0.25, 0.35, 0.2, 0.15, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_1_5_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.25, 0.35, 0.2, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSXQ9QFYzQ0CXGGsjtOjUqVu55U2r', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward for moving forward, scaled by the forward reward weight\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Reward for keeping the robot healthy (not falling over, and staying within healthy z range)\\n    healthy_reward = self.healthy_reward\\n    \\n    # Control cost penalizes the magnitude of action used, for energy efficiency\\n    ctrl_cost = self.control_cost(action)\\n    \\n    # Contact cost penalizes heavy contact forces which might imply collisions or unsafe interactions\\n    contact_cost = self.contact_cost\\n    \\n    # Total reward combines rewards and subtracts the costs\\n    reward = forward_reward + healthy_reward - ctrl_cost - contact_cost\\n\\n    # Detailed breakdown of the reward contributions\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```\\nThis reward function formulation encapsulates the task at hand: encouraging the agent (the Ant) to maximize its forward velocity while minimizing the use of control and undesired contact forces, and keeping itself within healthy operational states. The reward and costs are balanced to steer the learned policy towards these defined objectives.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746141353, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=271, prompt_tokens=1931, total_tokens=2202, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.25, 0.35, 0.2, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSXW6VsCqrvQv1yGLBRaraKELhFd5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.045, 0.40, 0.30, 0.20, 0.35, 0.25, 0.15, 0.009, 0.009, 0.009],\\n  \"description\": \"Optimized design with reduced material dimensions and moderately increased limb lengths for improved fitness function\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746141722, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=78, prompt_tokens=4139, total_tokens=4217, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.045, 0.4, 0.3, 0.2, 0.35, 0.25, 0.15, 0.009, 0.009, 0.009]\n",
      "Successfully saved GPTAnt_refine_1_5_1.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.045, 0.4, 0.3, 0.2, 0.35, 0.25, 0.15, 0.009, 0.009, 0.009]\n",
      "ChatCompletion(id='chatcmpl-BSXbrG07uV6XTxyLaPF1jBhDgrO4b', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Reward based on the forward velocity: encourage the ant to move forward\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # A static reward for maintaining a healthy state\\n    healthy_reward = self.healthy_reward\\n\\n    # Sum up the rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Costs associated with the control and contact forces\\n    ctrl_cost = self.control_cost(action)\\n    contact_cost = self.contact_cost\\n\\n    # Sum up the costs\\n    costs = ctrl_cost + contact_cost\\n\\n    # Compute the total reward: sum rewards and subtract costs\\n    reward = rewards - costs\\n\\n    # Information about individual components of the reward\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward,\\n    }\\n\\n    return reward, reward_info\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746142079, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=207, prompt_tokens=1931, total_tokens=2138, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.045, 0.4, 0.3, 0.2, 0.35, 0.25, 0.15, 0.009, 0.009, 0.009]\n",
      "ChatCompletion(id='chatcmpl-BSXhQ46GoKzOaQOefVMeEYRBU07f2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.04, 0.42, 0.32, 0.22, 0.37, 0.27, 0.17, 0.008, 0.008, 0.008],\\n  \"description\": \"Optimized design focusing on reduced material dimensions and finely tuned leg dimensions to enhance walking efficiency while maintaining lower material costs.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746142424, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=84, prompt_tokens=4139, total_tokens=4223, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.04, 0.42, 0.32, 0.22, 0.37, 0.27, 0.17, 0.008, 0.008, 0.008]\n",
      "Successfully saved GPTAnt_refine_1_5_2.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.04, 0.42, 0.32, 0.22, 0.37, 0.27, 0.17, 0.008, 0.008, 0.008]\n",
      "params: [0.1, 0.3, 0.2, 0.2, 0.3, 0.15, 0.1, 0.02, 0.02, 0.02]\n",
      "ChatCompletion(id='chatcmpl-BSXmsTdJNIIqjUnEgFVbkVixsCXdC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.05, 0.35, 0.25, 0.3, 0.25, 0.2, 0.15, 0.01, 0.01, 0.01],\\n  \"description\": \"Optimized for maximum walk distance with minimal material by fine-tuning leg lengths and keeping geom sizes minimal.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746142762, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=82, prompt_tokens=4141, total_tokens=4223, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.05, 0.35, 0.25, 0.3, 0.25, 0.2, 0.15, 0.01, 0.01, 0.01]\n",
      "Successfully saved GPTAnt_refine_0_5_0.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.3, 0.25, 0.2, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSXss4WvmTpVJb9UxoeEI8V4mkrH9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\ndef _get_rew(self, x_velocity: float, action):\\n    # Compute the forward movement reward: encourage the agent to move in the positive x-direction\\n    forward_reward = x_velocity * self._forward_reward_weight\\n    \\n    # Obtain a reward when the ant remains in the healthy range of states (e.g., not flipped over)\\n    healthy_reward = self.healthy_reward\\n    \\n    # Aggregate rewards\\n    rewards = forward_reward + healthy_reward\\n\\n    # Compute control cost based on the action taken by the agent to minimize excessive use of the actuators\\n    ctrl_cost = self.control_cost(action)\\n\\n    # Compute contact cost based on the forces experienced by the ant to discourage excessive force that could lead to failure\\n    contact_cost = self.contact_cost\\n\\n    # Aggregate costs\\n    costs = ctrl_cost + contact_cost\\n\\n    # Total reward calculation: rewards minus the penalties (costs)\\n    reward = rewards - costs\\n\\n    # Dictionary that logs individual components of the reward for further inspection and debugging\\n    reward_info = {\\n        \"reward_forward\": forward_reward,\\n        \"reward_ctrl\": -ctrl_cost,\\n        \"reward_contact\": -contact_cost,\\n        \"reward_survive\": healthy_reward\\n    }\\n\\n    return reward, reward_info\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746143134, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=259, prompt_tokens=1931, total_tokens=2190, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.35, 0.25, 0.3, 0.25, 0.2, 0.15, 0.01, 0.01, 0.01]\n",
      "ChatCompletion(id='chatcmpl-BSXywcCcztPE1urRSfRt3OQn8cCFD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"parameters\": [0.04, 0.38, 0.28, 0.33, 0.28, 0.23, 0.18, 0.009, 0.009, 0.009],\\n  \"description\": \"Optimized to enhance mobility while minimizing material costs by slightly increasing leg length and reducing material dimensions for efficiency.\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1746143510, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_5603ee5e2e', usage=CompletionUsage(completion_tokens=82, prompt_tokens=4141, total_tokens=4223, completion_tokens_details=None, prompt_tokens_details=None))\n",
      "[0.04, 0.38, 0.28, 0.33, 0.28, 0.23, 0.18, 0.009, 0.009, 0.009]\n",
      "Successfully saved GPTAnt_refine_0_5_1.xml\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.04, 0.38, 0.28, 0.33, 0.28, 0.23, 0.18, 0.009, 0.009, 0.009]\n"
     ]
    }
   ],
   "source": [
    "final_optimized_results = []  # 用来记录每个 coarse_best 的最优结果\n",
    "\n",
    "for rewardfunc_index, morphology_index in coarse_best:\n",
    "    \n",
    "    morphology = morphology_list[morphology_index]\n",
    "    parameter = parameter_list[morphology_index]\n",
    "    rewardfunc = rewardfunc_list[rewardfunc_index]\n",
    "    \n",
    "    best_efficiency = efficiency_matrix_select[rewardfunc_index][morphology_index]\n",
    "    best_fitness = fitness_matrix[rewardfunc_index][morphology_index]\n",
    "    best_morphology = morphology\n",
    "    best_parameter = parameter\n",
    "    best_rewardfunc = rewardfunc\n",
    "    best_material = compute_ant_volume(parameter)\n",
    "    \n",
    "    \n",
    "    logging.info(f\"Initial morphology:{morphology}\")\n",
    "    logging.info(f\"Initial parameter:{parameter}\" )\n",
    "    logging.info(f\"Initial rewardfunc:{rewardfunc}\" )\n",
    "    logging.info(f\"Initial fitness:{best_fitness}\" )\n",
    "    logging.info(f\"Initial efficiency:{best_efficiency}\" )\n",
    "    iteration = 0\n",
    "\n",
    "    while True:\n",
    "        improved = False  # 标记是否有改进，方便控制循环\n",
    "\n",
    "        designer = DGA()\n",
    "        \n",
    "         # -------- 优化 morphology --------\n",
    "        improved_morphology, improved_parameter = designer.improve_morphology(\n",
    "            best_parameter,\n",
    "            parameter_list,\n",
    "            efficiency_matrix_select[rewardfunc_index, :],\n",
    "            folder_name,\n",
    "            rewardfunc_index, \n",
    "            morphology_index,\n",
    "            iteration\n",
    "            \n",
    "        )\n",
    "\n",
    "        shutil.copy(improved_morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(best_rewardfunc, \"GPTrewardfunc.py\")\n",
    "        \n",
    "        import GPTrewardfunc\n",
    "        importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "        from GPTrewardfunc import _get_rew\n",
    "        GPTAntEnv._get_rew = _get_rew\n",
    "        \n",
    "        model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=5e5)\n",
    "        improved_fitness, _ = Eva(model_path)\n",
    "        improved_material = compute_ant_volume(improved_parameter)\n",
    "        improved_efficiency = improved_fitness / improved_material\n",
    "\n",
    "        if improved_efficiency > best_efficiency:\n",
    "\n",
    "            best_fitness = improved_fitness\n",
    "            best_morphology = improved_morphology\n",
    "            best_parameter = improved_parameter\n",
    "            best_material = improved_material\n",
    "            best_efficiency = improved_efficiency\n",
    "            improved = True\n",
    "            iteration +=1\n",
    "            logging.info(f\"Morphology optimization improved iteration {iteration}: material={improved_material}, fitness={improved_fitness}, efficiency={improved_efficiency}\")\n",
    "\n",
    "        # -------- 没有进一步改进，跳出循环 --------\n",
    "        if not improved:\n",
    "            logging.info(\"Not improved Morphology!\")\n",
    "            logging.info(\"____________________________________________\")\n",
    "            break\n",
    "            \n",
    "            \n",
    "        # -------- 优化 reward function --------\n",
    "        improved_rewardfunc = designer.improve_rewardfunc(\n",
    "            best_rewardfunc,\n",
    "            rewardfunc_list,\n",
    "            efficiency_matrix_select[:, morphology_index],\n",
    "            folder_name,\n",
    "            rewardfunc_index, \n",
    "            morphology_index,\n",
    "            iteration\n",
    "        )\n",
    "\n",
    "        shutil.copy(best_morphology, \"GPTAnt.xml\")\n",
    "        shutil.copy(improved_rewardfunc, \"GPTrewardfunc.py\")\n",
    "        \n",
    "        import GPTrewardfunc\n",
    "        importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "        from GPTrewardfunc import _get_rew\n",
    "        GPTAntEnv._get_rew = _get_rew\n",
    "        \n",
    "        model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=5e5)\n",
    "        improved_fitness, _ = Eva(model_path)\n",
    "        improved_material = compute_ant_volume(best_parameter)\n",
    "        improved_efficiency = improved_fitness / improved_material\n",
    "\n",
    "\n",
    "        if improved_efficiency > best_efficiency:\n",
    "            best_fitness = improved_fitness\n",
    "            best_rewardfunc = improved_rewardfunc\n",
    "            best_material = improved_material\n",
    "            best_efficiency = improved_efficiency\n",
    "            improved = True\n",
    "            iteration +=1\n",
    "            logging.info(f\"Reward optimization improved iteration {iteration}: material={improved_material}, fitness={improved_fitness}, efficiency={improved_efficiency}\")\n",
    "        \n",
    "        if not improved:\n",
    "            logging.info(\"Not improved Reward!\")\n",
    "            logging.info(\"____________________________________________\")\n",
    "            break\n",
    "            \n",
    "\n",
    "            \n",
    "    # 保存当前 coarse_best 的最终最优结果\n",
    "    final_optimized_results.append({\n",
    "        \"best_morphology\": best_morphology,\n",
    "        \"best_parameter\": best_parameter,\n",
    "        \"best_rewardfunc\": best_rewardfunc,\n",
    "        \"best_fitness\": best_fitness,\n",
    "        \"best_material\": best_material,\n",
    "        \"best_efficiency\": best_efficiency,\n",
    "        \"best_iteration\":iteration\n",
    "    })\n",
    "\n",
    "    logging.info(f\"Final optimized result: rewardfunc_index{rewardfunc_index} morphology_index{morphology_index}\")\n",
    "    logging.info(f\"  Morphology: {best_morphology}\")\n",
    "    logging.info(f\"  Parameter: {best_parameter}\")\n",
    "    logging.info(f\"  Rewardfunc: {best_rewardfunc}\")\n",
    "    logging.info(f\"  Fitness: {best_fitness}\")\n",
    "    logging.info(f\"  Material: {best_material}\")\n",
    "    logging.info(f\"  Efficiency: {best_efficiency}\")\n",
    "    logging.info(\"____________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f\"{final_optimized_results}\")\n",
    "\n",
    "# logging.info(f\"fine optimization end: best material cost: {best_material}  fitness: {improved_fitness} merterial_efficiency: {improved_material_efficiency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_3_5_0.xml',\n",
       "  'best_parameter': [0.09,\n",
       "   0.31,\n",
       "   0.21,\n",
       "   0.21,\n",
       "   0.31,\n",
       "   0.16,\n",
       "   0.11,\n",
       "   0.019,\n",
       "   0.019,\n",
       "   0.019],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_3_5_1.py',\n",
       "  'best_fitness': 96.37197499675398,\n",
       "  'best_material': 0.007676419799560828,\n",
       "  'best_efficiency': 12554.28670045735,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_3_17_0.xml',\n",
       "  'best_parameter': [0.06,\n",
       "   0.42,\n",
       "   0.22,\n",
       "   0.27,\n",
       "   0.22,\n",
       "   0.17,\n",
       "   0.17,\n",
       "   0.012,\n",
       "   0.012,\n",
       "   0.012],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_3_17_1.py',\n",
       "  'best_fitness': 104.8561836284059,\n",
       "  'best_material': 0.002914886734590455,\n",
       "  'best_efficiency': 35972.644282913556,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_1_17_2.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.42,\n",
       "   0.22,\n",
       "   0.25,\n",
       "   0.2,\n",
       "   0.15,\n",
       "   0.15,\n",
       "   0.008,\n",
       "   0.008,\n",
       "   0.008],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_1_17_3.py',\n",
       "  'best_fitness': 125.65966942413843,\n",
       "  'best_material': 0.001358744912070929,\n",
       "  'best_efficiency': 92482.16372903611,\n",
       "  'best_iteration': 4},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_1_24_3.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.35,\n",
       "   0.25,\n",
       "   0.17,\n",
       "   0.02,\n",
       "   0.13,\n",
       "   0.05,\n",
       "   0.015,\n",
       "   0.01,\n",
       "   0.01],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_1_24_2.py',\n",
       "  'best_fitness': 116.43831902814877,\n",
       "  'best_material': 0.002219913754502376,\n",
       "  'best_efficiency': 52451.73097017456,\n",
       "  'best_iteration': 4},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_2_5_0.xml',\n",
       "  'best_parameter': [0.09,\n",
       "   0.31,\n",
       "   0.21,\n",
       "   0.21,\n",
       "   0.31,\n",
       "   0.16,\n",
       "   0.11,\n",
       "   0.015,\n",
       "   0.015,\n",
       "   0.015],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_2_5_1.py',\n",
       "  'best_fitness': 78.05572694659769,\n",
       "  'best_material': 0.005889630514443509,\n",
       "  'best_efficiency': 13253.077040261991,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_0_17_0.xml',\n",
       "  'best_parameter': [0.05,\n",
       "   0.45,\n",
       "   0.25,\n",
       "   0.3,\n",
       "   0.25,\n",
       "   0.18,\n",
       "   0.18,\n",
       "   0.01,\n",
       "   0.01,\n",
       "   0.01],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_0_17_1.py',\n",
       "  'best_fitness': 54.18305771868858,\n",
       "  'best_material': 0.0020313778099937943,\n",
       "  'best_efficiency': 26673.057789704864,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_3_24_1.xml',\n",
       "  'best_parameter': [0.09,\n",
       "   0.33,\n",
       "   0.28,\n",
       "   0.17,\n",
       "   0.03,\n",
       "   0.13,\n",
       "   0.05,\n",
       "   0.019,\n",
       "   0.012,\n",
       "   0.013],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTrewardfunc_3.py',\n",
       "  'best_fitness': 128.69191813752713,\n",
       "  'best_material': 0.005805790028289808,\n",
       "  'best_efficiency': 22166.133723481467,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_2_17_0.xml',\n",
       "  'best_parameter': [0.05, 0.35, 0.25, 0.2, 0.25, 0.2, 0.2, 0.01, 0.01, 0.01],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_2_17_1.py',\n",
       "  'best_fitness': 57.40182794614118,\n",
       "  'best_material': 0.0018721150916498602,\n",
       "  'best_efficiency': 30661.484543428374,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_1_5_1.xml',\n",
       "  'best_parameter': [0.045,\n",
       "   0.4,\n",
       "   0.3,\n",
       "   0.2,\n",
       "   0.35,\n",
       "   0.25,\n",
       "   0.15,\n",
       "   0.009,\n",
       "   0.009,\n",
       "   0.009],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTrewardfunc_1.py',\n",
       "  'best_fitness': 69.85107039236362,\n",
       "  'best_material': 0.0016343633006690515,\n",
       "  'best_efficiency': 42739.010576026165,\n",
       "  'best_iteration': 2},\n",
       " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_0_5_0.xml',\n",
       "  'best_parameter': [0.05, 0.35, 0.25, 0.3, 0.25, 0.2, 0.15, 0.01, 0.01, 0.01],\n",
       "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTrewardfunc_0.py',\n",
       "  'best_fitness': 50.427336114219585,\n",
       "  'best_material': 0.0019192560207599422,\n",
       "  'best_efficiency': 26274.418612610392,\n",
       "  'best_iteration': 1}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_optimized_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26274.418612610392"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_efficiency"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " {'best_morphology': 'results/Div_m25_r5/assets/GPTAnt_refine_1_17_2.xml',\n",
    "  'best_parameter': [0.05,\n",
    "   0.42,\n",
    "   0.22,\n",
    "   0.25,\n",
    "   0.2,\n",
    "   0.15,\n",
    "   0.15,\n",
    "   0.008,\n",
    "   0.008,\n",
    "   0.008],\n",
    "  'best_rewardfunc': 'results/Div_m25_r5/env/GPTAnt_refine_1_17_3.py',\n",
    "  'best_fitness': 125.65966942413843,\n",
    "  'best_material': 0.001358744912070929,\n",
    "  'best_efficiency': 92482.16372903611,\n",
    "  'best_iteration': 4},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.05, 0.42, 0.22, 0.25, 0.2, 0.15, 0.15, 0.008, 0.008, 0.008]\n",
      "best 5e5 steps train\n",
      "\n",
      "fitness:12.711915884268283\n",
      "efficiency:9355.63089976428\n"
     ]
    }
   ],
   "source": [
    "# best\n",
    "\n",
    "morphology = \"results/Div_m25_r5/assets/GPTAnt_refine_1_17_2.xml\"\n",
    "rewardfunc = \"results/Div_m25_r5/env/GPTAnt_refine_1_17_3.py\"\n",
    "morphology_index=999\n",
    "rewardfunc_index=999\n",
    "\n",
    "parameter = [0.05,\n",
    "   0.42,\n",
    "   0.22,\n",
    "   0.25,\n",
    "   0.2,\n",
    "   0.15,\n",
    "   0.15,\n",
    "   0.008,\n",
    "   0.008,\n",
    "   0.008]\n",
    "\n",
    "shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "shutil.copy(rewardfunc, \"GPTrewardfunc.py\")\n",
    "\n",
    "import GPTrewardfunc\n",
    "importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "from GPTrewardfunc import _get_rew\n",
    "GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "# model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=5e5)\n",
    "# model_path = r\"results/Div_m25_r5/fine/SAC_morphology17_rewardfunc1_500000.0steps\"\n",
    "model_path = f\"results/Div_m25_r5/fine/SAC_morphology{morphology_index}_rewardfunc{rewardfunc_index}_1000000.0steps\"\n",
    "fitness, _ = Eva(model_path)\n",
    "material = compute_ant_volume(parameter)\n",
    "efficiency = fitness / material\n",
    "logging.info(\"best 5e5 steps train\\n\")\n",
    "logging.info(f\"fitness:{fitness}\")\n",
    "logging.info(f\"efficiency:{efficiency}\")\n",
    "print(\"best 5e5 steps train\\n\")\n",
    "print(f\"fitness:{fitness}\")\n",
    "print(f\"efficiency:{efficiency}\")\n",
    "\n",
    "# logging.info(\"best 1e6 steps train\\n\")\n",
    "# logging.info(f\"fitness:{fitness}\")\n",
    "# logging.info(f\"efficiency:{efficiency}\")\n",
    "# print(\"best 1e6 steps train\\n\")\n",
    "# print(f\"fitness:{fitness}\")\n",
    "# print(f\"efficiency:{efficiency}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.25, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.08, 0.08, 0.08]\n",
      "human 1e6 steps train\n",
      "\n",
      "fitness:4.759975363633909\n",
      "efficiency:26.12844135029237\n"
     ]
    }
   ],
   "source": [
    "# human\n",
    "\n",
    "morphology = \"results/Div_m25_r5/assets/GPTAnt_25.xml\"\n",
    "rewardfunc = \"results/Div_m25_r5/env/GPTrewardfunc_5.py\"\n",
    "morphology_index=888\n",
    "rewardfunc_index=888\n",
    "\n",
    "parameter = [0.25, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.08, 0.08, 0.08]\n",
    "\n",
    "shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "shutil.copy(rewardfunc, \"GPTrewardfunc.py\")\n",
    "\n",
    "import GPTrewardfunc\n",
    "importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "from GPTrewardfunc import _get_rew\n",
    "GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=1e6)\n",
    "# model_path = f\"results/Div_m25_r5/fine/SAC_morphology{morphology_index}_rewardfunc{rewardfunc_index}_500000.0steps\"\n",
    "fitness, _ = Eva(model_path)\n",
    "material = compute_ant_volume(parameter)\n",
    "efficiency = fitness / material\n",
    "\n",
    "logging.info(\"human 1e6 steps train\\n\")\n",
    "logging.info(f\"fitness:{fitness}\")\n",
    "logging.info(f\"efficiency:{efficiency}\")\n",
    "print(\"human 1e6 steps train\\n\")\n",
    "print(f\"fitness:{fitness}\")\n",
    "print(f\"efficiency:{efficiency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.14, 0.42, 0.24, 0.52, 0.32, 0.32, 0.18, 0.025, 0.045, 0.025]\n",
      "eureka 1e6 steps train\n",
      "\n",
      "fitness:41.52058573178679\n",
      "efficiency:1160.943968668064\n"
     ]
    }
   ],
   "source": [
    "# Eureka morphlogy\n",
    "\n",
    "morphology = \"results/Eureka_morphology/assets/GPTAnt_8.xml\"\n",
    "rewardfunc = \"results/Eureka_morphology/env/GPTrewardfunc_5.py\"\n",
    "\n",
    "morphology_index=222\n",
    "rewardfunc_index=222\n",
    "\n",
    "parameter = [0.14, 0.42, 0.24, 0.52, 0.32, 0.32, 0.18, 0.025, 0.045, 0.025]\n",
    "\n",
    "shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "shutil.copy(rewardfunc, \"GPTrewardfunc.py\")\n",
    "\n",
    "import GPTrewardfunc\n",
    "importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "from GPTrewardfunc import _get_rew\n",
    "GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=1e6)\n",
    "# model_path = f\"results/Div_m25_r5/fine/SAC_morphology{morphology_index}_rewardfunc{rewardfunc_index}_500000.0steps\"\n",
    "fitness, _ = Eva(model_path)\n",
    "material = compute_ant_volume(parameter)\n",
    "efficiency = fitness / material\n",
    "\n",
    "logging.info(\"eureka morphlogy 1e6 steps train\\n\")\n",
    "logging.info(f\"fitness:{fitness}\")\n",
    "logging.info(f\"efficiency:{efficiency}\")\n",
    "print(\"eureka morphlogy 1e6 steps train\\n\")\n",
    "print(f\"fitness:{fitness}\")\n",
    "print(f\"efficiency:{efficiency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.25, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.08, 0.08, 0.08]\n",
      "eureka 1e6 steps train\n",
      "\n",
      "fitness:4.538256740359049\n",
      "efficiency:24.9113842014751\n"
     ]
    }
   ],
   "source": [
    "# Eureka\n",
    "\n",
    "morphology = \"results/Eureka/assets/GPTAnt_25.xml\"\n",
    "rewardfunc = \"results/Eureka/env/GPTAnt_5_1.py\"\n",
    "\n",
    "morphology_index=111\n",
    "rewardfunc_index=111\n",
    "\n",
    "parameter = [0.25, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.08, 0.08, 0.08]\n",
    "\n",
    "shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "shutil.copy(rewardfunc, \"GPTrewardfunc.py\")\n",
    "\n",
    "import GPTrewardfunc\n",
    "importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "from GPTrewardfunc import _get_rew\n",
    "GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=1e6)\n",
    "# model_path = f\"results/Div_m25_r5/fine/SAC_morphology{morphology_index}_rewardfunc{rewardfunc_index}_500000.0steps\"\n",
    "fitness, _ = Eva(model_path)\n",
    "material = compute_ant_volume(parameter)\n",
    "efficiency = fitness / material\n",
    "\n",
    "logging.info(\"eureka 1e6 steps train\\n\")\n",
    "logging.info(f\"fitness:{fitness}\")\n",
    "logging.info(f\"efficiency:{efficiency}\")\n",
    "print(\"eureka 1e6 steps train\\n\")\n",
    "print(f\"fitness:{fitness}\")\n",
    "print(f\"efficiency:{efficiency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " {'best_morphology': 'results/noDiv_m25_r5/assets/GPTAnt_refine_4_2_2.xml',\n",
    "  'best_parameter': [0.1,\n",
    "   0.25,\n",
    "   0.17,\n",
    "   0.25,\n",
    "   0.15,\n",
    "   0.12,\n",
    "   0.18,\n",
    "   0.03,\n",
    "   0.03,\n",
    "   0.03],\n",
    "  'best_rewardfunc': 'results/noDiv_m25_r5/env/GPTrewardfunc_4.py',\n",
    "  'best_fitness': 67.6709174730936,\n",
    "  'best_material': 0.014709160909209498,\n",
    "  'best_efficiency': 4600.5967227351775,\n",
    "  'best_iteration': 3},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "params: [0.1, 0.25, 0.17, 0.25, 0.15, 0.12, 0.18, 0.03, 0.03, 0.03]\n",
      "no div 5e5 steps train\n",
      "\n",
      "fitness:6.790701302781278\n",
      "efficiency:461.664764203482\n"
     ]
    }
   ],
   "source": [
    "# no div\n",
    "\n",
    "morphology = \"results/noDiv_m25_r5/assets/GPTAnt_refine_4_2_2.xml\"\n",
    "rewardfunc = \"results/noDiv_m25_r5/env/GPTrewardfunc_4.py\"\n",
    "\n",
    "morphology_index=333\n",
    "rewardfunc_index=333\n",
    "\n",
    "parameter = [0.1,\n",
    "   0.25,\n",
    "   0.17,\n",
    "   0.25,\n",
    "   0.15,\n",
    "   0.12,\n",
    "   0.18,\n",
    "   0.03,\n",
    "   0.03,\n",
    "   0.03]\n",
    "\n",
    "shutil.copy(morphology, \"GPTAnt.xml\")\n",
    "shutil.copy(rewardfunc, \"GPTrewardfunc.py\")\n",
    "\n",
    "import GPTrewardfunc\n",
    "importlib.reload(GPTrewardfunc)  # 重新加载模块\n",
    "from GPTrewardfunc import _get_rew\n",
    "GPTAntEnv._get_rew = _get_rew\n",
    "\n",
    "model_path = Train(morphology_index, rewardfunc_index, folder_name, stage='fine', total_timesteps=5e5)\n",
    "# model_path = f\"results/Div_m25_r5/fine/SAC_morphology{morphology_index}_rewardfunc{rewardfunc_index}_500000.0steps\"\n",
    "fitness, _ = Eva(model_path)\n",
    "material = compute_ant_volume(parameter)\n",
    "efficiency = fitness / material\n",
    "\n",
    "logging.info(\"no div 5e5 steps train\\n\")\n",
    "logging.info(f\"fitness:{fitness}\")\n",
    "logging.info(f\"efficiency:{efficiency}\")\n",
    "print(\"no div 5e5 steps train\\n\")\n",
    "print(f\"fitness:{fitness}\")\n",
    "print(f\"efficiency:{efficiency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodesign",
   "language": "python",
   "name": "robodesign"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
